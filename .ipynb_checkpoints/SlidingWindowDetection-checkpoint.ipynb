{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "#         self.pool = nn.MaxPool2d(2,2)\n",
    "#         self.conv1 = nn.Conv2d(3,6,5,stride=1,padding=(2,2))\n",
    "#         self.conv2 = nn.Conv2d(6,18,5,stride=1,padding=(2,2))\n",
    "#         self.conv3 = nn.Conv2d(18,27,5,stride=1,padding=(2,2))\n",
    "#         self.conv4 = nn.Conv2d(27,34,5,stride=1,padding=(2,2))\n",
    "#         self.fc1 = nn.Linear(6 * 10 * 34, 1024) \n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, 256)\n",
    "#         self.fc4 = nn.Linear(256,2)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv1 = nn.Conv2d(3,6,5,stride=1)\n",
    "        self.conv2 = nn.Conv2d(6,18,5,stride=1)\n",
    "        self.conv3 = nn.Conv2d(18,27,5,stride=1)\n",
    "        self.fc1 = nn.Linear(17 * 33 * 27, 512) \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 104)\n",
    "        self.fc4 = nn.Linear(104,2)        \n",
    "\n",
    "    def forward(self, x):\n",
    "#         print('shape',x.data.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "#         print('first layer:',x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "#         print('second layer:',x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "#         print('third layer:',x)\n",
    "#         print(x.data.shape)\n",
    "        x = x.view(-1, 17 * 33 * 27)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "#         print('result: ',x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# def outputToTensor(labels):\n",
    "#     # print(labels)\n",
    "#     # print(labels.numpy().astype(int))\n",
    "#     tmp = labels.numpy().astype(int)\n",
    "#     # print([ np.where(r==1)[0][0] for r in tmp ])\n",
    "#     tmp = [ np.where(r==1)[0][0] for r in tmp ]\n",
    "#     tmp = np.array(tmp)\n",
    "#     tmp = torch.from_numpy(tmp)\n",
    "#     # print(tmp)\n",
    "#     return tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (conv1): Conv2d (3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d (6, 18, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d (18, 27, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=15147, out_features=512)\n",
      "  (fc2): Linear(in_features=512, out_features=256)\n",
      "  (fc3): Linear(in_features=256, out_features=104)\n",
      "  (fc4): Linear(in_features=104, out_features=2)\n",
      ")\n",
      "Enter model name : first\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'models/'\n",
    "net = Net()\n",
    "net = net.double()\n",
    "net = net.cuda()\n",
    "print(net)\n",
    "name = input(\"Enter model name : \")\n",
    "PATH = MODEL_PATH + name\n",
    "net = torch.load(PATH)\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [cv2.imread('test images/' + x) for x in os.listdir('test images/')]\n",
    "# print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH = 96\n",
    "IM_HEIGHT = 160\n",
    "STRIDE = 5\n",
    "\n",
    "def normalize(data):\n",
    "    data = np.divide(data,255)\n",
    "    data = data - 0.5\n",
    "    return data\n",
    "\n",
    "def predictHumanSub(data):\n",
    "    output = net(data)\n",
    "    return output[0]\n",
    "\n",
    "def predictHuman(image):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
