{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SlidingWindowCNN.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "GAJ4XC-0idwc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print 'Files in Drive:'\n",
        "!ls drive/\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVoJ7275ibep",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y__nku4TjL96",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "JUcrHzRRiaZH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 11
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "f1eeac6c-d6f3-4109-85da-5d6f8cd2cd1d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1517793188581,
          "user_tz": -420,
          "elapsed": 27292,
          "user": {
            "displayName": "Chanokthorn Uerpairojkit",
            "photoUrl": "//lh3.googleusercontent.com/-lxOXQMW2xGM/AAAAAAAAAAI/AAAAAAAAAFM/6xYN4f5kB5I/s50-c-k-no/photo.jpg",
            "userId": "114952678521276212047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# https://opencv.org/\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "import cv2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libxext6:amd64.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 18070 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libxext6_2%3a1.3.3-1_amd64.deb ...\n",
            "Unpacking libxext6:amd64 (2:1.3.3-1) ...\n",
            "Selecting previously unselected package x11-common.\n",
            "Preparing to unpack .../x11-common_1%3a7.7+19ubuntu3_all.deb ...\n",
            "Unpacking x11-common (1:7.7+19ubuntu3) ...\n",
            "Selecting previously unselected package libice6:amd64.\n",
            "Preparing to unpack .../libice6_2%3a1.0.9-2_amd64.deb ...\n",
            "Unpacking libice6:amd64 (2:1.0.9-2) ...\n",
            "Selecting previously unselected package libsm6:amd64.\n",
            "Preparing to unpack .../libsm6_2%3a1.2.2-1_amd64.deb ...\n",
            "Unpacking libsm6:amd64 (2:1.2.2-1) ...\n",
            "Setting up libxext6:amd64 (2:1.3.3-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2) ...\n",
            "Setting up x11-common (1:7.7+19ubuntu3) ...\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libice6:amd64 (2:1.0.9-2) ...\n",
            "Setting up libsm6:amd64 (2:1.2.2-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2pErYr6zoAiU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "#         self.pool = nn.MaxPool2d(2,2)\n",
        "#         self.conv1 = nn.Conv2d(3,6,5,stride=1,padding=(2,2))\n",
        "#         self.conv2 = nn.Conv2d(6,18,5,stride=1,padding=(2,2))\n",
        "#         self.conv3 = nn.Conv2d(18,27,5,stride=1,padding=(2,2))\n",
        "#         self.conv4 = nn.Conv2d(27,34,5,stride=1,padding=(2,2))\n",
        "#         self.fc1 = nn.Linear(6 * 10 * 34, 1024) \n",
        "#         self.fc2 = nn.Linear(1024, 512)\n",
        "#         self.fc3 = nn.Linear(512, 256)\n",
        "#         self.fc4 = nn.Linear(256,2)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv1 = nn.Conv2d(3,6,5,stride=1)\n",
        "        self.conv2 = nn.Conv2d(6,18,5,stride=1)\n",
        "        self.conv3 = nn.Conv2d(18,27,5,stride=1)\n",
        "        self.fc1 = nn.Linear(17 * 33 * 27, 512) \n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 104)\n",
        "        self.fc4 = nn.Linear(104,2)        \n",
        "\n",
        "    def forward(self, x):\n",
        "#         print('shape',x.data.shape)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "#         print('first layer:',x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "#         print('second layer:',x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "#         print('third layer:',x)\n",
        "#         print(x.data.shape)\n",
        "        x = x.view(-1, 17 * 33 * 27)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "#         print('result: ',x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# def outputToTensor(labels):\n",
        "#     # print(labels)\n",
        "#     # print(labels.numpy().astype(int))\n",
        "#     tmp = labels.numpy().astype(int)\n",
        "#     # print([ np.where(r==1)[0][0] for r in tmp ])\n",
        "#     tmp = [ np.where(r==1)[0][0] for r in tmp ]\n",
        "#     tmp = np.array(tmp)\n",
        "#     tmp = torch.from_numpy(tmp)\n",
        "#     # print(tmp)\n",
        "#     return tmp\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wmZq_QUHpP_a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "018fd441-0a96-4c76-b51b-8d63d186c889",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1517793198775,
          "user_tz": -420,
          "elapsed": 9172,
          "user": {
            "displayName": "Chanokthorn Uerpairojkit",
            "photoUrl": "//lh3.googleusercontent.com/-lxOXQMW2xGM/AAAAAAAAAAI/AAAAAAAAAFM/6xYN4f5kB5I/s50-c-k-no/photo.jpg",
            "userId": "114952678521276212047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "MODEL_PATH = 'drive/Colab Notebooks/'\n",
        "net = Net()\n",
        "net = net.double()\n",
        "# net = net.cuda()\n",
        "\n",
        "# name = input(\"Enter model name : \")\n",
        "name = 'first'\n",
        "PATH = MODEL_PATH + name\n",
        "# net = torch.load(PATH)\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "net = net.cuda()\n",
        "print(net)\n",
        "print('loaded')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
            "  (conv1): Conv2d (3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d (6, 18, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d (18, 27, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=15147, out_features=512)\n",
            "  (fc2): Linear(in_features=512, out_features=256)\n",
            "  (fc3): Linear(in_features=256, out_features=104)\n",
            "  (fc4): Linear(in_features=104, out_features=2)\n",
            ")\n",
            "loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t7S3ArpIxmQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "u6FM30HdjYf0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "images = [cv2.imread('drive/test images/' + x) for x in os.listdir('drive/test images/')]\n",
        "# print(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F9v7eebYvOPk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5aa086a-5e70-4407-ea3b-9518fde2a308",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1517763247483,
          "user_tz": -420,
          "elapsed": 859,
          "user": {
            "displayName": "Chanokthorn Uerpairojkit",
            "photoUrl": "//lh3.googleusercontent.com/-lxOXQMW2xGM/AAAAAAAAAAI/AAAAAAAAAFM/6xYN4f5kB5I/s50-c-k-no/photo.jpg",
            "userId": "114952678521276212047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(os.listdir('drive/test images/')[5])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dn-lg.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "md1Q_XAVmFET",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import operator\n",
        "\n",
        "CROP_WIDTH = 96\n",
        "CROP_HEIGHT = 160\n",
        "STRIDE = 50\n",
        "COLLECT = 5\n",
        "\n",
        "def normalize(data):\n",
        "    data = np.divide(data,255)\n",
        "    data = data - 0.5\n",
        "    data = np.transpose(data,(2,1,0))\n",
        "    return data\n",
        "\n",
        "def predictHuman(image,scale = 1):\n",
        "  im_width = image.shape[1]\n",
        "  im_height = image.shape[0]\n",
        "  storage = {}\n",
        "  j = 0\n",
        "  booler = True\n",
        "  while ( j + CROP_HEIGHT <= im_height):\n",
        "    i = 0\n",
        "    while (i + CROP_WIDTH <= im_width):\n",
        "      subimage = image[j : j + CROP_HEIGHT , i : i + CROP_WIDTH]\n",
        "#       imgplot = plt.imshow(subimage)\n",
        "#       plt.show()\n",
        "      subimage = normalize(subimage)\n",
        "      subimage = Variable(torch.from_numpy(subimage).double().cuda())\n",
        "      subimage = subimage.unsqueeze(0)\n",
        "      output = net(subimage)\n",
        "      storage[(i,j,scale)] = output.cpu().data.numpy()[0][0]\n",
        "      i += STRIDE\n",
        "      \n",
        "    j += STRIDE\n",
        "  sorted_storage = sorted(storage.items(), key=operator.itemgetter(1),reverse=True)\n",
        "#   print(sorted_storage)\n",
        "  \n",
        "#   while( i + CROP_WIDTH <= im_width and j + CROP_HEIGHT <= im_height):\n",
        "#     subimage = image[j : j + CROP_HEIGHT , i : i + CROP_WIDTH]\n",
        "#     subimage = normalize(subimage)\n",
        "#     subimage = Variable(torch.from_numpy(subimage).double().cuda())\n",
        "#     subimage = subimage.unsqueeze(0)\n",
        "#     output = net(subimage)\n",
        "#     print(output)\n",
        "#     storage[(i,j)] = output.cpu().data.numpy()\n",
        "#     i += STRIDE\n",
        "#     j += STRIDE\n",
        "#   print(storage)\n",
        "  sorted_storage = sorted_storage[0:COLLECT]\n",
        "  return sorted_storage\n",
        "# predictHuman(images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bNHmB6-QjmnD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 5
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "1c973dcd-844f-4107-e3b4-a39b19769bbc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1517797448551,
          "user_tz": -420,
          "elapsed": 15508,
          "user": {
            "displayName": "Chanokthorn Uerpairojkit",
            "photoUrl": "//lh3.googleusercontent.com/-lxOXQMW2xGM/AAAAAAAAAAI/AAAAAAAAAFM/6xYN4f5kB5I/s50-c-k-no/photo.jpg",
            "userId": "114952678521276212047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "AMOUNT_OF_RECTS = 5\n",
        "\n",
        "def predictMultiScale(image):\n",
        "  width = image.shape[1]\n",
        "  height = image.shape[0]\n",
        "  scales = [4,3,2,1,0.8,0.5,0.4]\n",
        "  storage = {}\n",
        "  for scale in scales:\n",
        "    if(scale < 1):\n",
        "      subimage = cv2.resize(image, (0,0), fx=scale, fy=scale) \n",
        "    else:\n",
        "      subimage = cv2.resize(image, (scale*width, scale*height), interpolation = cv2.INTER_CUBIC)\n",
        "    storage.update(predictHuman(subimage,scale))\n",
        "    print(scale)\n",
        "  sorted_storage = sorted(storage.items(), key=operator.itemgetter(1),reverse=True)\n",
        "  return sorted_storage[0:AMOUNT_OF_RECTS]\n",
        "\n",
        "\n",
        "def locateHuman(image):\n",
        "  result = predictMultiScale(image)\n",
        "  coords = np.ndarray((AMOUNT_OF_RECTS * 2,2))\n",
        "#   coords = ()\n",
        "  counter = 0\n",
        "  for a in result:\n",
        "    i = a[0][0]\n",
        "    j = a[0][1]\n",
        "    scale = a[0][2]\n",
        "#     coords += ((int(i * scale), int(j * scale)), (int(i * scale) + CROP_WIDTH, int(j * scale) + CROP_HEIGHT) )\n",
        "    coords[counter, :] = np.array([int(i * scale), int(j * scale)])\n",
        "    coords[counter + 1, :] = np.array([int(i * scale) + CROP_WIDTH, int(j * scale) + CROP_HEIGHT])\n",
        "    counter += 2\n",
        "  coords = coords.astype(int)\n",
        "  print(coords)\n",
        "  return coords\n",
        "coords = locateHuman(images[5])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "0.8\n",
            "0.5\n",
            "0.4\n",
            "[[ 5400     0]\n",
            " [ 5496   160]\n",
            " [10800   200]\n",
            " [10896   360]\n",
            " [ 4200  1600]\n",
            " [ 4296  1760]\n",
            " [ 3500     0]\n",
            " [ 3596   160]\n",
            " [11200   200]\n",
            " [11296   360]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VMTVcqhjqiM8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "4761131b-ab2b-4f2b-fd95-bbab2d6f880b",
        "executionInfo": {
          "status": "error",
          "timestamp": 1517797947567,
          "user_tz": -420,
          "elapsed": 669,
          "user": {
            "displayName": "Chanokthorn Uerpairojkit",
            "photoUrl": "//lh3.googleusercontent.com/-lxOXQMW2xGM/AAAAAAAAAAI/AAAAAAAAAFM/6xYN4f5kB5I/s50-c-k-no/photo.jpg",
            "userId": "114952678521276212047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def process(image):\n",
        "  coords = locateHuman(image)\n",
        "  x,y,w,h = cv2.boundingRect(coords)\n",
        "  cv2.rectangle(image,(x,y),(w,h),(0,255,0),2)\n",
        "#   cv2.imshow(\"Image\", image)\n",
        "  imgplot = plt.imshow(img)\n",
        "process(images[5])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-593dfebef411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_yAlEyTNkytZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "78c5c5f3-6835-43d0-80b0-ef26250f5831",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1517796978316,
          "user_tz": -420,
          "elapsed": 830,
          "user": {
            "displayName": "Chanokthorn Uerpairojkit",
            "photoUrl": "//lh3.googleusercontent.com/-lxOXQMW2xGM/AAAAAAAAAAI/AAAAAAAAAFM/6xYN4f5kB5I/s50-c-k-no/photo.jpg",
            "userId": "114952678521276212047"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(tmp[0:5][0][0])\n",
        "a = (1,2,3)\n",
        "b = (4,5,6)\n",
        "a += b\n",
        "print(a)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1800, 0, 3)\n",
            "(1, 2, 3, 4, 5, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G1myvswPnxG5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}