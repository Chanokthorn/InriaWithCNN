{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "#         self.pool = nn.MaxPool2d(2,2)\n",
    "#         self.conv1 = nn.Conv2d(3,6,5,stride=1,padding=(2,2))\n",
    "#         self.conv2 = nn.Conv2d(6,18,5,stride=1,padding=(2,2))\n",
    "#         self.conv3 = nn.Conv2d(18,27,5,stride=1,padding=(2,2))\n",
    "#         self.conv4 = nn.Conv2d(27,34,5,stride=1,padding=(2,2))\n",
    "#         self.fc1 = nn.Linear(6 * 10 * 34, 1024) \n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, 256)\n",
    "#         self.fc4 = nn.Linear(256,2)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv1 = nn.Conv2d(3,6,5,stride=1)\n",
    "        self.conv2 = nn.Conv2d(6,18,5,stride=1)\n",
    "        self.conv3 = nn.Conv2d(18,27,5,stride=1)\n",
    "        self.fc1 = nn.Linear(17 * 33 * 27, 512) \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 104)\n",
    "        self.fc4 = nn.Linear(104,2)        \n",
    "\n",
    "    def forward(self, x):\n",
    "#         print('shape',x.data.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "#         print('first layer:',x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "#         print('second layer:',x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "#         print('third layer:',x)\n",
    "#         print(x.data.shape)\n",
    "        x = x.view(-1, 17 * 33 * 27)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "#         print('result: ',x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# def outputToTensor(labels):\n",
    "#     # print(labels)\n",
    "#     # print(labels.numpy().astype(int))\n",
    "#     tmp = labels.numpy().astype(int)\n",
    "#     # print([ np.where(r==1)[0][0] for r in tmp ])\n",
    "#     tmp = [ np.where(r==1)[0][0] for r in tmp ]\n",
    "#     tmp = np.array(tmp)\n",
    "#     tmp = torch.from_numpy(tmp)\n",
    "#     # print(tmp)\n",
    "#     return tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (conv1): Conv2d (3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d (6, 18, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d (18, 27, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=15147, out_features=512)\n",
      "  (fc2): Linear(in_features=512, out_features=256)\n",
      "  (fc3): Linear(in_features=256, out_features=104)\n",
      "  (fc4): Linear(in_features=104, out_features=2)\n",
      ")\n",
      "Enter model name : first\n",
      "OrderedDict([('conv1.weight', \n",
      "(0 ,0 ,.,.) = \n",
      " -0.0557 -0.0259  0.0001  0.0503 -0.1238\n",
      "  0.0775 -0.0235  0.0696 -0.1456 -0.1329\n",
      "  0.1225  0.0406 -0.0272 -0.0204 -0.0779\n",
      "  0.0201 -0.0373 -0.0335 -0.1438 -0.1495\n",
      "  0.1652  0.0774  0.0676  0.0378 -0.0094\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  0.1460  0.0159 -0.0242 -0.1766 -0.0752\n",
      "  0.0906  0.1349 -0.0561 -0.2021 -0.1294\n",
      "  0.0936  0.0303  0.0681 -0.0200 -0.1832\n",
      "  0.0985  0.0992  0.0601 -0.1882 -0.2179\n",
      " -0.0324 -0.0167  0.0439 -0.0921 -0.0662\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "  0.2179  0.1510  0.0294 -0.0972 -0.1833\n",
      "  0.1568  0.0774 -0.0372  0.0596 -0.1391\n",
      "  0.0485  0.0791  0.0033 -0.0948 -0.1853\n",
      "  0.1353  0.2243  0.0346  0.0483  0.0292\n",
      "  0.1689  0.0689  0.1380 -0.0239 -0.1609\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  0.0381  0.0537 -0.0368  0.0298 -0.0998\n",
      " -0.0278 -0.0847  0.1208 -0.1095 -0.1113\n",
      "  0.1271  0.0428  0.0309  0.0787  0.0275\n",
      " -0.0436 -0.0522  0.1215  0.0774  0.0044\n",
      " -0.0547  0.1444 -0.0940  0.0234 -0.0131\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "  0.1251  0.0543  0.1171  0.0762  0.1074\n",
      " -0.0824  0.0301  0.0350 -0.0802 -0.0723\n",
      "  0.0817 -0.0216  0.0687  0.0593  0.0803\n",
      "  0.0820 -0.0733  0.0531  0.0324  0.0687\n",
      " -0.0241  0.0720 -0.0764 -0.0482  0.0557\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "  0.0713  0.0400 -0.0642 -0.0169 -0.0302\n",
      " -0.0624 -0.1277  0.0248 -0.0906  0.0453\n",
      " -0.1132  0.0220 -0.0811 -0.0306 -0.1201\n",
      "  0.0271 -0.0324 -0.0091  0.0627 -0.0754\n",
      "  0.0669  0.0631 -0.0468  0.0702 -0.1335\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  0.0861 -0.0014  0.0937 -0.0231 -0.0556\n",
      " -0.0008  0.1364  0.0003 -0.0913  0.1206\n",
      "  0.0249 -0.0296 -0.0778 -0.0046 -0.0634\n",
      " -0.0241  0.0880  0.0889 -0.0612  0.0152\n",
      "  0.1238  0.0023  0.1226  0.1076  0.0094\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -0.0437 -0.0645  0.0129 -0.0195 -0.1281\n",
      " -0.0937 -0.1081 -0.1296 -0.0297 -0.0558\n",
      "  0.0667 -0.0903 -0.0370 -0.1777 -0.0090\n",
      "  0.0223 -0.1225 -0.0883 -0.1390 -0.1592\n",
      "  0.1012 -0.0661 -0.0503 -0.0175 -0.1601\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      " -0.0682 -0.0467 -0.1549  0.0551 -0.0390\n",
      " -0.0246  0.0287 -0.1291 -0.0168 -0.0818\n",
      "  0.1110 -0.1386 -0.1296 -0.0999 -0.0160\n",
      "  0.1460 -0.0051 -0.1473 -0.1827 -0.1668\n",
      "  0.0019 -0.0962  0.0363 -0.0076 -0.0936\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      " -0.0610  0.0135  0.0242  0.1750  0.1419\n",
      " -0.0260 -0.0289  0.1070  0.0182  0.2016\n",
      " -0.0949 -0.0477 -0.0308  0.0025  0.0548\n",
      " -0.0344  0.0641  0.0734  0.0437  0.1815\n",
      " -0.1001  0.0452 -0.0186 -0.0163  0.2042\n",
      "\n",
      "(3 ,1 ,.,.) = \n",
      " -0.1094 -0.1214  0.1013  0.0401 -0.0409\n",
      " -0.0721  0.0248 -0.0406 -0.0258 -0.0640\n",
      " -0.0799 -0.0208 -0.0132  0.1137  0.0567\n",
      "  0.0143 -0.0291 -0.1277  0.0977 -0.0202\n",
      " -0.0417  0.0343  0.0062 -0.0408  0.1399\n",
      "\n",
      "(3 ,2 ,.,.) = \n",
      "  0.0381  0.1525  0.1990  0.1681  0.0737\n",
      "  0.1162  0.1753  0.2356  0.0750  0.1153\n",
      "  0.1250  0.0860  0.1466  0.1290  0.1328\n",
      "  0.0454  0.1756  0.1745  0.0345  0.1963\n",
      "  0.1816  0.2073  0.1211  0.0768  0.2330\n",
      "\n",
      "(4 ,0 ,.,.) = \n",
      "  0.0567  0.1005 -0.0668 -0.0329  0.0710\n",
      "  0.1112 -0.0740 -0.1003 -0.0051 -0.1222\n",
      "  0.0541  0.0916  0.0044  0.0582 -0.0353\n",
      "  0.1153  0.1048  0.0359  0.0722  0.0415\n",
      "  0.1683  0.0829 -0.0129 -0.0708  0.0619\n",
      "\n",
      "(4 ,1 ,.,.) = \n",
      " -0.1271 -0.1643 -0.1663 -0.0176 -0.0869\n",
      " -0.0846  0.0317  0.0318 -0.0046 -0.1078\n",
      " -0.0397 -0.0298 -0.1193 -0.1978 -0.1662\n",
      " -0.0105 -0.0563 -0.0047 -0.1072 -0.0953\n",
      "  0.0856 -0.1036 -0.1254 -0.1512 -0.1847\n",
      "\n",
      "(4 ,2 ,.,.) = \n",
      " -0.0789 -0.0191  0.0363 -0.1194 -0.1643\n",
      "  0.0138 -0.0911  0.0582 -0.1835  0.0252\n",
      " -0.0515  0.0867 -0.0989 -0.1144 -0.1288\n",
      "  0.0570  0.0935 -0.0913 -0.0313 -0.1593\n",
      "  0.0408 -0.0134  0.0380 -0.1287  0.0006\n",
      "\n",
      "(5 ,0 ,.,.) = \n",
      "  0.1512  0.1478  0.1630  0.1155  0.1629\n",
      "  0.0241  0.0948 -0.0459  0.0931  0.0941\n",
      "  0.0552  0.0255 -0.0477  0.0947 -0.0387\n",
      "  0.0978 -0.0600 -0.0601 -0.1122  0.0689\n",
      "  0.0609 -0.1014  0.0305 -0.0732  0.1230\n",
      "\n",
      "(5 ,1 ,.,.) = \n",
      " -0.0274 -0.1794 -0.2098 -0.0914 -0.1310\n",
      " -0.1268 -0.0519 -0.1957 -0.0724 -0.0280\n",
      " -0.1258 -0.2671 -0.2574 -0.1377 -0.1111\n",
      " -0.0128 -0.1457 -0.1418 -0.0785 -0.0942\n",
      " -0.0762 -0.0525 -0.1387 -0.0762 -0.0202\n",
      "\n",
      "(5 ,2 ,.,.) = \n",
      " -0.0586 -0.1667 -0.1358 -0.1867 -0.0272\n",
      " -0.2113 -0.1647 -0.2068 -0.2488 -0.1952\n",
      " -0.0413 -0.0979 -0.1361 -0.2285 -0.1808\n",
      " -0.2088 -0.0990 -0.1724 -0.1607 -0.2179\n",
      " -0.1244 -0.1685 -0.2292 -0.2280 -0.1061\n",
      "[torch.cuda.DoubleTensor of size 6x3x5x5 (GPU 0)]\n",
      "), ('conv1.bias', \n",
      "-0.0153\n",
      " 0.0376\n",
      "-0.4756\n",
      "-0.0598\n",
      "-0.4385\n",
      "-0.9074\n",
      "[torch.cuda.DoubleTensor of size 6 (GPU 0)]\n",
      "), ('conv2.weight', \n",
      "(0 ,0 ,.,.) = \n",
      "  4.5487e-02 -3.7785e-02 -8.3685e-02 -5.8766e-02 -6.4679e-02\n",
      "  8.2978e-02 -1.2835e-02 -5.6713e-04  1.8501e-02  4.3673e-02\n",
      "  8.2844e-02 -1.8149e-02  4.0077e-03  4.9286e-02 -3.9895e-02\n",
      "  1.2998e-01  5.2489e-02 -8.9004e-02  5.3904e-02  1.0998e-01\n",
      " -4.7115e-03  3.4532e-02 -3.6270e-03  1.3701e-02  1.1768e-01\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  3.2603e-02 -7.7944e-02 -5.8216e-03 -6.4166e-02 -2.8735e-02\n",
      "  7.6263e-02 -4.6813e-02  9.2277e-03  1.4615e-02  4.6328e-02\n",
      " -3.0008e-02 -7.3267e-02 -4.0017e-02 -1.8759e-02 -7.4170e-02\n",
      " -6.1790e-02 -6.2873e-02 -6.2733e-02  2.9611e-02 -4.2688e-02\n",
      "  4.1703e-02  1.5042e-02 -2.4609e-02 -6.8284e-02 -7.6088e-02\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      " -1.5134e-02  2.9512e-03 -8.6511e-02  6.5682e-03  1.1873e-03\n",
      "  1.9257e-02  4.1113e-02  3.1868e-02  7.3906e-02  5.4385e-02\n",
      "  1.5889e-02  3.6010e-02  3.8125e-02  5.1676e-02 -2.9995e-02\n",
      "  1.4029e-02  9.9911e-03  3.6064e-02  2.7982e-02 -1.4088e-02\n",
      " -1.1434e-01  5.3710e-02 -4.2099e-02  5.7930e-02  2.6746e-02\n",
      "\n",
      "(0 ,3 ,.,.) = \n",
      " -1.8191e-01 -9.3424e-02 -1.0067e-01 -2.5540e-02  2.5974e-02\n",
      " -2.0566e-01 -1.8370e-01 -6.7694e-02  6.7234e-02  4.0630e-02\n",
      " -1.4688e-01 -1.2099e-01  7.0611e-02  9.7428e-02  5.6241e-02\n",
      " -1.6515e-01 -7.4003e-03  1.6701e-01  1.1744e-01  6.6730e-02\n",
      " -1.9065e-01 -2.2698e-02  1.8816e-01  1.5588e-01  1.7696e-01\n",
      "\n",
      "(0 ,4 ,.,.) = \n",
      " -9.2250e-05 -1.3311e-02  6.0010e-02  5.7263e-02  1.4094e-02\n",
      " -1.3524e-02 -6.5019e-02 -7.8086e-02 -1.3118e-02 -6.0474e-02\n",
      "  5.2027e-02 -8.1898e-02 -4.9803e-02 -2.9110e-02  8.5842e-03\n",
      "  4.0872e-02 -1.4058e-02  4.7982e-02 -7.3753e-02  3.1305e-02\n",
      " -7.6574e-02 -4.8043e-02 -1.7572e-02 -3.3845e-02  8.5934e-03\n",
      "\n",
      "(0 ,5 ,.,.) = \n",
      "  5.0003e-02 -6.5434e-02 -7.9930e-02 -1.5437e-02  8.3875e-03\n",
      "  5.2604e-02 -7.1332e-02 -1.0358e-03 -4.5999e-02 -6.6020e-02\n",
      "  4.9436e-02 -1.0113e-01 -1.1665e-02  2.5945e-02 -9.2365e-02\n",
      "  4.8997e-04 -2.7440e-02 -5.5330e-02 -1.3322e-02  1.6339e-02\n",
      " -4.2921e-02  2.0702e-02 -9.0054e-03  4.5555e-02  2.4447e-02\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -6.9538e-02 -1.5376e-02  5.0418e-02  2.1292e-02 -1.0268e-01\n",
      " -5.8458e-02  1.0388e-01  1.5520e-02 -1.1119e-01 -1.1863e-01\n",
      " -6.9745e-02  9.6543e-03  5.8398e-02  5.4480e-02 -1.5475e-01\n",
      " -6.7967e-02  1.3154e-01  1.5034e-01  1.4126e-02 -1.0286e-01\n",
      " -2.9864e-02  9.9358e-02  1.1133e-01  1.0620e-01 -1.1429e-01\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "  1.2692e-02  3.1093e-02  3.1975e-02  2.6371e-03 -5.0364e-02\n",
      " -3.9000e-02  2.7708e-02  4.0717e-02  5.6733e-02  2.7505e-02\n",
      "  4.9991e-03 -8.5358e-03 -2.4419e-02 -3.4903e-02  1.5110e-02\n",
      "  4.1857e-02 -1.7247e-02  4.7595e-02 -8.5079e-02 -5.0909e-02\n",
      " -1.7960e-02 -2.4668e-02 -2.9272e-02  6.9691e-04 -5.3351e-04\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      " -5.5871e-02 -2.8516e-04  1.0274e-02  9.1442e-02 -7.8771e-02\n",
      "  3.2323e-02 -7.0237e-02  7.7122e-02  3.8529e-02  1.4314e-02\n",
      " -1.0363e-01 -1.9573e-02  6.0286e-02  6.7255e-02  9.4847e-02\n",
      " -7.8930e-02 -1.9717e-02  6.5274e-02  1.0087e-01 -5.4185e-02\n",
      "  8.2013e-03 -2.4817e-02 -3.8250e-02  6.3610e-02 -6.6399e-02\n",
      "\n",
      "(1 ,3 ,.,.) = \n",
      "  9.0701e-02  7.7049e-02 -5.7140e-02 -4.3543e-02  2.1876e-02\n",
      "  7.5084e-02 -6.4024e-02 -8.8752e-02 -1.1976e-01  4.0490e-02\n",
      "  7.7364e-02  7.9041e-02 -9.5277e-02 -1.1816e-01 -7.1926e-02\n",
      "  1.7435e-01  9.7955e-03 -7.7848e-02 -8.6324e-02 -3.9460e-02\n",
      "  1.6318e-01  1.0153e-02  1.7409e-02 -9.6058e-02 -1.4008e-02\n",
      "\n",
      "(1 ,4 ,.,.) = \n",
      "  6.5895e-02  5.6476e-02 -5.8028e-03 -6.6976e-02 -8.3751e-02\n",
      " -4.1034e-02  8.0480e-02  2.5058e-02 -2.6032e-02  4.7165e-02\n",
      " -9.6533e-02  7.6882e-02  2.3580e-02  5.0979e-02 -7.0845e-02\n",
      "  5.4905e-02 -1.0248e-03 -2.4395e-03  9.6002e-02  4.8643e-02\n",
      "  4.0941e-02 -6.3388e-02  6.9507e-02  8.7316e-02  2.6255e-02\n",
      "\n",
      "(1 ,5 ,.,.) = \n",
      " -1.7548e-01 -9.7932e-02 -4.1520e-02  1.2266e-01  4.0973e-02\n",
      " -6.5615e-02 -1.0624e-01 -3.8770e-02  1.3447e-01  1.3740e-01\n",
      " -1.1316e-01 -5.2913e-02  6.2880e-02  1.6259e-01  1.0450e-01\n",
      " -1.8760e-01 -9.1553e-02 -1.8228e-02  1.8000e-01  1.3918e-01\n",
      " -1.9504e-01 -1.7297e-01  1.7875e-02  6.5846e-03  4.0850e-02\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  4.8372e-02 -3.6661e-02 -2.8828e-02  9.0761e-04 -6.3913e-02\n",
      " -2.8034e-02 -2.8962e-02  1.1071e-02 -1.0338e-02  8.7953e-03\n",
      " -1.6283e-02  4.5325e-02  5.7552e-02 -5.6850e-02  3.5188e-02\n",
      "  9.5222e-03  4.1847e-03 -6.0301e-02  5.6557e-02  1.3941e-02\n",
      " -7.5209e-02 -7.7295e-02 -6.9155e-02 -6.5983e-02 -8.7946e-03\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -3.2095e-02 -6.3837e-02 -2.8426e-03 -1.3425e-02 -5.2807e-02\n",
      " -6.5227e-02 -2.6220e-02 -7.7070e-02 -6.0756e-02 -6.2259e-02\n",
      "  3.7184e-02 -3.9393e-02 -3.4337e-02  3.3842e-02  7.3369e-02\n",
      " -4.1504e-02  7.4811e-02  8.4657e-03  2.8857e-03 -6.9967e-02\n",
      " -7.8143e-02 -5.5996e-03 -4.8926e-03 -6.8008e-02  7.0893e-02\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      " -8.1312e-02  5.7160e-02  1.1403e-02 -2.5980e-02  1.3983e-02\n",
      "  3.3027e-05 -6.2894e-02  3.7271e-02  2.8802e-02 -3.4637e-02\n",
      " -2.3359e-02 -4.3766e-02  3.1414e-02 -3.4670e-02 -7.5313e-02\n",
      " -6.1877e-02 -3.9997e-02 -3.9323e-02 -2.7169e-02 -6.7033e-02\n",
      " -6.7141e-03 -5.0893e-02 -6.6198e-02 -7.8291e-02 -6.8652e-02\n",
      "\n",
      "(2 ,3 ,.,.) = \n",
      " -7.1884e-02  1.8874e-02 -3.8912e-02  2.4493e-03 -1.4444e-02\n",
      " -5.9029e-02  3.5943e-02  2.2920e-02  1.2065e-02  4.4207e-02\n",
      "  2.7470e-02 -4.1080e-02 -6.0337e-02  1.9849e-02 -9.6912e-02\n",
      " -8.4321e-02 -7.2816e-02 -6.3558e-02 -5.7146e-02 -1.5686e-02\n",
      " -3.8706e-03  3.5546e-02  3.9840e-02 -8.4756e-02 -3.7606e-02\n",
      "\n",
      "(2 ,4 ,.,.) = \n",
      " -8.4164e-02 -8.7985e-02 -3.7766e-02 -6.3280e-02 -2.3810e-02\n",
      "  3.6962e-02 -2.5734e-02 -7.3158e-02  5.1792e-02 -1.8391e-02\n",
      " -1.8179e-02 -4.7777e-02  5.8172e-02  1.3999e-02 -1.7567e-02\n",
      " -5.2214e-02  3.1323e-02  1.7836e-02 -4.2159e-02  1.6260e-03\n",
      " -2.0017e-02 -3.2581e-03  4.9105e-02 -7.2374e-02  7.4622e-03\n",
      "\n",
      "(2 ,5 ,.,.) = \n",
      "  4.8864e-02 -6.6933e-04 -7.5130e-03 -5.8866e-02 -5.3079e-02\n",
      "  4.4719e-02  8.0920e-04 -6.6893e-02  6.5426e-02  6.4715e-03\n",
      " -7.0825e-02  5.7585e-02 -5.2567e-02 -3.3401e-02 -8.2272e-02\n",
      " -7.0874e-02 -1.7493e-02 -1.5775e-02  3.6235e-02 -4.7078e-02\n",
      " -3.9834e-02 -8.3522e-02 -1.0638e-02  1.1177e-02 -3.9151e-02\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(15,0 ,.,.) = \n",
      "  6.9169e-02  3.6668e-02  4.9342e-02 -1.1327e-02 -5.2660e-02\n",
      " -3.7414e-02  9.0514e-02  2.4981e-02 -3.3166e-02 -1.5573e-02\n",
      "  1.8490e-02 -1.8594e-02 -7.3373e-02 -6.1387e-02  1.8361e-02\n",
      "  5.3669e-02  9.9869e-03  2.4553e-02  4.5732e-02 -6.5554e-02\n",
      "  5.5436e-02  3.7934e-02 -6.1007e-02  4.9153e-02 -1.3762e-03\n",
      "\n",
      "(15,1 ,.,.) = \n",
      "  6.4038e-02 -4.2354e-02  3.7067e-03 -6.7033e-02  3.4921e-02\n",
      " -1.9142e-03  3.5725e-02 -4.0839e-02 -6.8983e-02  4.1799e-02\n",
      " -1.3186e-03  6.4495e-02  4.5949e-02  5.9355e-02 -5.4952e-02\n",
      "  2.1821e-02  1.0146e-03  3.7391e-03 -4.4746e-02  2.9403e-02\n",
      "  6.5635e-02 -4.7324e-02 -3.2677e-02 -4.7358e-02  1.1713e-02\n",
      "\n",
      "(15,2 ,.,.) = \n",
      "  1.5079e-02 -5.9812e-02 -1.4209e-03 -5.0731e-02 -6.5734e-02\n",
      "  1.7736e-02  2.3101e-02 -6.3994e-02 -3.0737e-02  4.8894e-02\n",
      "  5.6511e-02  4.4350e-02 -6.0279e-02  6.2979e-02  6.0278e-02\n",
      "  4.2308e-02  7.8543e-03  1.8989e-02  7.0010e-02 -7.9777e-02\n",
      " -6.1157e-02 -6.6257e-02  4.3885e-02 -3.3126e-02  7.1877e-02\n",
      "\n",
      "(15,3 ,.,.) = \n",
      "  4.8935e-04 -5.0245e-02  6.5191e-02 -4.9391e-02  3.5505e-02\n",
      "  5.6317e-02 -5.4044e-02  7.1704e-02 -3.5440e-02 -1.8122e-02\n",
      " -3.0095e-02 -8.5388e-02 -6.5092e-02 -3.9546e-02 -1.6832e-02\n",
      "  2.6697e-02 -8.1600e-02 -7.8401e-02  3.9853e-02  2.1384e-02\n",
      "  6.7066e-02 -8.1620e-02 -5.8008e-02  3.3022e-02 -9.3661e-02\n",
      "\n",
      "(15,4 ,.,.) = \n",
      " -2.6728e-02  7.5445e-02  2.7514e-03  2.5666e-02  7.3155e-04\n",
      "  5.9911e-02 -7.1904e-02  4.8620e-04  7.3650e-02 -2.8974e-02\n",
      "  2.4048e-02  1.9575e-02  6.1873e-02  4.2517e-02  5.6274e-02\n",
      "  6.9108e-02  4.4299e-02  4.3514e-02 -2.6734e-03  1.5165e-02\n",
      " -4.8240e-02  1.9553e-02  7.8492e-02 -4.0881e-02 -3.2621e-02\n",
      "\n",
      "(15,5 ,.,.) = \n",
      " -3.9262e-02 -5.2428e-02 -5.1035e-02 -5.0786e-04 -9.2124e-03\n",
      " -3.2997e-04  3.9877e-03  3.5248e-02 -8.0071e-02 -3.4716e-02\n",
      "  1.3634e-02  5.5109e-02 -2.3327e-02 -8.3041e-02 -5.4208e-02\n",
      " -8.7223e-04  4.3427e-02 -7.0559e-02  3.1741e-02 -4.4936e-02\n",
      "  8.9834e-03  6.5178e-02 -4.1370e-02 -8.0956e-02 -1.7285e-02\n",
      "     ⋮ \n",
      "\n",
      "(16,0 ,.,.) = \n",
      " -7.0463e-02  6.8927e-02  6.8594e-02  6.3660e-02  3.5591e-02\n",
      " -5.2548e-02  4.7547e-02  4.4587e-02  3.4369e-02  2.9956e-02\n",
      " -9.8041e-03  2.0197e-02  6.2251e-02  3.8154e-02 -5.0915e-03\n",
      "  5.4281e-02  8.6837e-03 -6.7073e-02  1.0384e-02  5.1012e-02\n",
      "  6.7673e-02 -5.1555e-02  9.4139e-03 -4.7854e-02  4.2647e-02\n",
      "\n",
      "(16,1 ,.,.) = \n",
      "  2.8363e-02  5.2073e-02 -9.7088e-03 -6.0591e-02 -6.7223e-02\n",
      "  3.4176e-02  6.1599e-03  3.8908e-02 -1.2046e-02  4.6025e-02\n",
      "  1.0895e-02  1.0546e-02 -2.7649e-02 -4.3432e-02  3.2336e-02\n",
      "  4.8527e-02  1.7783e-02 -5.1643e-02 -3.1916e-03 -4.6204e-02\n",
      " -2.5184e-02  7.9010e-03  1.7493e-02 -6.4417e-03 -3.6414e-02\n",
      "\n",
      "(16,2 ,.,.) = \n",
      " -1.0501e-01 -1.9149e-02 -2.3631e-02 -2.7848e-02  3.0404e-02\n",
      " -8.4460e-02  3.2748e-02  4.6574e-02 -6.0920e-02 -3.9469e-02\n",
      " -6.7582e-02 -7.7013e-02  6.2330e-02  6.4067e-02  5.1596e-02\n",
      "  2.7915e-02 -8.6172e-02  3.9055e-02  1.4303e-03  9.4251e-02\n",
      " -3.1246e-02  1.9783e-02  3.0892e-02  1.1023e-02 -3.9656e-02\n",
      "\n",
      "(16,3 ,.,.) = \n",
      " -1.1008e-01 -1.1218e-01  2.3335e-02  3.6240e-02  6.0494e-02\n",
      " -1.2273e-01 -4.0900e-02  7.2942e-02  1.1202e-01  4.4107e-02\n",
      " -1.3062e-01 -1.1093e-01 -3.2678e-02  1.4794e-01  1.1530e-01\n",
      " -1.7660e-01 -1.5033e-01  6.4202e-02  5.9906e-02  1.3119e-01\n",
      " -1.3516e-01 -4.1779e-02  8.4645e-02  1.5302e-01  1.4443e-01\n",
      "\n",
      "(16,4 ,.,.) = \n",
      " -3.4200e-02  2.0130e-02 -3.5638e-02  7.3261e-02  6.3414e-02\n",
      "  3.4836e-02 -2.8517e-02 -4.9199e-02  5.9927e-02 -4.1480e-02\n",
      " -6.1168e-02  2.1507e-02 -3.1123e-02  1.1636e-02  1.8966e-02\n",
      "  6.8133e-02  5.7178e-02 -2.9930e-02  3.1549e-02 -3.2773e-02\n",
      " -1.0385e-02  5.7946e-02 -1.2933e-02  1.1824e-02  1.3840e-02\n",
      "\n",
      "(16,5 ,.,.) = \n",
      " -1.2951e-02 -3.0674e-02 -6.1452e-02 -6.9132e-02 -1.7580e-02\n",
      "  5.9072e-02 -6.9425e-02  5.7385e-02  3.1832e-02 -5.1920e-02\n",
      "  5.5551e-02 -7.8809e-02 -1.3456e-02  5.1723e-03 -4.9081e-02\n",
      "  4.2717e-02 -2.1055e-02  6.6505e-02 -7.8757e-02 -6.5872e-02\n",
      "  2.6789e-02  1.0985e-02 -3.8714e-02  6.0307e-03  4.8475e-04\n",
      "     ⋮ \n",
      "\n",
      "(17,0 ,.,.) = \n",
      " -5.2319e-02  1.6504e-03  5.2646e-02 -5.1655e-02 -8.6070e-02\n",
      " -1.4490e-02 -1.9052e-02 -7.4972e-02  4.6486e-02  5.8365e-02\n",
      "  5.4419e-02 -1.2051e-02  2.7834e-02  4.3983e-02 -8.2013e-02\n",
      " -3.6426e-02  8.1567e-02 -8.5647e-03  5.4899e-02 -3.8132e-02\n",
      " -5.3920e-02  3.7633e-02  9.1037e-02  4.3144e-02 -5.7262e-02\n",
      "\n",
      "(17,1 ,.,.) = \n",
      " -1.1214e-02  2.0850e-04 -6.1318e-02 -2.4427e-02 -6.1826e-02\n",
      " -2.1732e-02 -7.7345e-02  6.3685e-03 -7.6474e-03 -5.6294e-02\n",
      " -7.1447e-02  6.0629e-02  7.0312e-02 -2.5206e-02  2.0737e-02\n",
      "  5.3863e-02 -1.6661e-02  5.1510e-02  4.6393e-02  7.8358e-03\n",
      "  6.1704e-02  2.7897e-02  3.3410e-02 -7.7530e-02 -4.4586e-02\n",
      "\n",
      "(17,2 ,.,.) = \n",
      "  2.0300e-02  7.3712e-02  3.8820e-02 -7.8607e-02 -4.3543e-02\n",
      " -1.5894e-02  8.2876e-02  7.5696e-02 -6.9479e-03 -5.4831e-02\n",
      "  8.9995e-02  1.0091e-01 -5.0294e-02 -4.0769e-02 -6.9688e-02\n",
      "  4.6533e-02  4.3185e-02 -2.1256e-02 -1.0746e-02  2.0184e-02\n",
      "  4.8446e-02 -5.8240e-02  6.0804e-02 -3.3246e-02 -3.6731e-02\n",
      "\n",
      "(17,3 ,.,.) = \n",
      "  5.5109e-03 -3.7694e-02  9.9054e-03  6.0879e-02 -4.1228e-02\n",
      " -5.6201e-02  6.8225e-02 -3.5738e-02 -2.1720e-02 -1.0469e-01\n",
      " -5.1037e-02  9.9808e-03  5.4041e-03  1.9133e-02  4.1578e-02\n",
      " -2.5253e-02 -1.6176e-02  3.2418e-02 -4.0897e-02  5.3567e-02\n",
      "  9.8204e-02 -3.7237e-02 -8.4632e-04 -7.0709e-02 -5.6825e-02\n",
      "\n",
      "(17,4 ,.,.) = \n",
      " -7.2390e-02  8.4039e-02 -5.7148e-02 -1.5909e-02  4.8775e-02\n",
      "  5.0594e-02  8.9262e-02 -7.5063e-02 -7.6581e-02  5.8490e-02\n",
      "  6.7381e-02 -3.2833e-03  1.8808e-02 -6.1284e-02 -8.9062e-02\n",
      "  9.3412e-03 -1.3484e-02 -4.4348e-02 -5.8505e-02  1.5256e-02\n",
      "  8.2943e-02  7.3925e-02  2.8261e-02  4.2277e-02  6.9078e-02\n",
      "\n",
      "(17,5 ,.,.) = \n",
      " -2.5208e-02 -9.1530e-02 -4.0913e-02 -1.0219e-01 -9.6277e-02\n",
      " -3.2322e-02 -1.0077e-01 -4.5869e-02 -3.4265e-02  7.6298e-03\n",
      "  4.8413e-02 -4.7828e-02  2.9672e-02  2.0691e-02 -3.5902e-02\n",
      "  3.7108e-02 -2.4811e-02  4.4840e-02  3.9910e-02 -6.2538e-02\n",
      " -7.8046e-02 -8.3461e-02 -3.4308e-02  1.5523e-03  3.5872e-02\n",
      "[torch.cuda.DoubleTensor of size 18x6x5x5 (GPU 0)]\n",
      "), ('conv2.bias', \n",
      "-0.0674\n",
      "-0.1091\n",
      " 0.0363\n",
      " 0.0452\n",
      "-0.0478\n",
      "-0.2213\n",
      "-0.0084\n",
      " 0.0844\n",
      "-0.0833\n",
      "-0.1249\n",
      "-0.0961\n",
      "-0.1188\n",
      "-0.0636\n",
      "-0.0819\n",
      " 0.0704\n",
      "-0.1464\n",
      "-0.1240\n",
      "-0.0520\n",
      "[torch.cuda.DoubleTensor of size 18 (GPU 0)]\n",
      "), ('conv3.weight', \n",
      "(0 ,0 ,.,.) = \n",
      " -3.9131e-02  4.4331e-02  3.0842e-02 -3.2181e-02 -1.3634e-02\n",
      " -5.1927e-04  2.7716e-02  2.7713e-03 -5.1052e-02 -5.5500e-02\n",
      "  2.3379e-02 -1.5789e-02 -2.3814e-02 -3.7679e-02 -7.8124e-03\n",
      "  4.7272e-02 -6.8506e-03 -5.8115e-03  2.4310e-02 -2.3237e-02\n",
      " -1.1287e-02 -3.4772e-02  3.7284e-03 -5.6881e-02  2.4022e-02\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -2.0998e-02  5.6111e-03  4.7678e-02 -7.7829e-02 -8.5813e-02\n",
      " -5.4062e-02  4.3898e-02  9.5861e-02  4.4281e-02 -7.2020e-02\n",
      " -1.3064e-01 -1.7381e-02  1.0797e-01  7.2218e-02 -7.0194e-02\n",
      " -9.5793e-02 -2.1925e-02  5.4984e-02  6.5927e-02 -7.0186e-02\n",
      " -7.8651e-02 -8.7100e-02  2.9639e-02  5.9025e-02 -6.2673e-02\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      " -2.1817e-02 -1.0316e-02 -3.4082e-02 -3.4375e-02  3.1105e-02\n",
      "  3.1363e-02  1.3504e-02  2.8028e-02  3.7164e-02  4.0144e-02\n",
      " -3.7930e-02 -6.5763e-03  3.1414e-02  7.9426e-03 -1.7794e-02\n",
      "  3.7227e-02 -1.9884e-02 -5.1910e-02 -3.0964e-02  3.8543e-02\n",
      " -3.6817e-03  3.8597e-02  1.6645e-02 -4.7285e-02 -2.7837e-02\n",
      "   ...\n",
      "\n",
      "(0 ,15,.,.) = \n",
      "  1.0554e-03  1.2717e-02  2.6355e-03  1.3500e-02 -1.9378e-02\n",
      " -5.6368e-03 -3.9438e-03  1.5299e-02 -4.2795e-02 -3.3582e-02\n",
      " -2.8495e-02 -2.2787e-02 -3.9111e-03 -5.1372e-02 -7.5693e-03\n",
      "  1.6296e-02  3.5988e-02  3.8008e-02  2.4776e-02 -4.5994e-02\n",
      "  2.7966e-02  3.0033e-02 -3.2609e-02  1.8396e-02 -8.5322e-03\n",
      "\n",
      "(0 ,16,.,.) = \n",
      " -9.0729e-03 -2.0940e-03 -1.9456e-02 -3.9029e-03 -4.3092e-02\n",
      "  4.7630e-02  4.6788e-02  6.7461e-03 -1.9059e-02 -5.4575e-02\n",
      "  2.3027e-02 -3.6334e-02 -2.5651e-02 -5.7886e-02  2.8959e-02\n",
      " -2.1213e-02  4.5957e-02  2.9783e-02  3.5842e-04 -1.2892e-02\n",
      " -2.3952e-02  1.5679e-02 -2.5036e-02 -7.3622e-03 -4.2994e-02\n",
      "\n",
      "(0 ,17,.,.) = \n",
      "  2.8140e-02  1.6373e-02 -7.2326e-03 -3.4091e-02 -5.3565e-02\n",
      "  3.8996e-03  3.2806e-02  1.1846e-02  1.7362e-02 -1.0039e-02\n",
      " -2.1580e-02  4.3810e-02  3.9495e-02 -1.9907e-02 -5.1144e-03\n",
      "  1.1596e-02  4.9170e-02 -1.0563e-02 -4.5222e-02 -1.2351e-02\n",
      " -3.3599e-02 -1.7407e-02  2.3819e-02 -2.3943e-02 -1.7511e-02\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  2.1711e-02  2.7941e-02 -2.1581e-02 -3.0492e-03  1.5817e-02\n",
      " -3.9703e-02  4.3200e-02  1.2553e-02 -4.3016e-02  1.3207e-02\n",
      "  2.5867e-03 -1.4642e-02 -7.5059e-03 -1.2552e-02  6.5774e-03\n",
      "  3.3310e-02  1.6050e-02 -2.5131e-02 -4.6295e-02 -3.0158e-02\n",
      " -1.6346e-02 -1.1202e-02 -3.2136e-02 -1.0507e-02 -1.8182e-03\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      " -2.4723e-02 -4.2080e-02 -2.0926e-04  2.9843e-02 -4.2717e-02\n",
      " -4.9197e-03 -4.3621e-02 -1.8594e-02  1.3098e-02 -1.3957e-03\n",
      " -3.5735e-02 -3.8592e-02  6.7458e-03 -3.6898e-02  4.2376e-02\n",
      "  2.3035e-02 -9.4046e-03  4.8258e-03 -3.1297e-02 -2.3744e-02\n",
      " -4.3252e-02  3.6430e-02 -1.6206e-02  9.5329e-03  5.5692e-02\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "  3.4372e-02  6.7386e-03 -1.6415e-02  4.7518e-03  3.5349e-02\n",
      " -4.2369e-02 -4.4185e-02  4.2947e-02 -1.0899e-02  3.4511e-02\n",
      "  2.9396e-02  3.0947e-03  1.0490e-02 -1.2737e-02 -4.0358e-03\n",
      " -4.2007e-02 -3.7203e-02  4.7291e-03 -4.7331e-03 -1.9846e-02\n",
      " -1.5887e-02  3.8056e-03  4.0785e-02  3.9416e-02 -3.6101e-02\n",
      "   ...\n",
      "\n",
      "(1 ,15,.,.) = \n",
      " -1.1828e-02 -3.4385e-02  1.2393e-02  2.9034e-02 -1.1161e-02\n",
      "  2.1526e-02  4.5310e-03 -2.2987e-02  3.7810e-02  2.4173e-03\n",
      "  4.2309e-02 -3.7981e-02  2.2280e-02 -4.5668e-02 -1.5327e-02\n",
      "  3.4177e-02 -1.7053e-02 -4.3498e-02 -2.8673e-02  2.4609e-02\n",
      "  4.7548e-02 -7.8009e-03 -4.8471e-03 -3.7919e-02 -4.5637e-02\n",
      "\n",
      "(1 ,16,.,.) = \n",
      "  1.3703e-02 -1.7678e-02 -2.8810e-02 -3.1786e-02 -3.9897e-02\n",
      "  3.2879e-04 -2.0191e-02  2.0589e-02 -5.7393e-03  3.3615e-02\n",
      "  6.1987e-03  3.0789e-02  4.1219e-02 -1.9091e-02  2.8090e-02\n",
      " -1.0089e-03 -3.8711e-03 -1.2974e-02 -2.9879e-02 -1.0305e-02\n",
      "  2.7138e-02 -3.4390e-02 -1.8611e-02  4.7588e-02 -2.1642e-02\n",
      "\n",
      "(1 ,17,.,.) = \n",
      " -4.0170e-02  2.7858e-02 -1.6386e-02  4.6793e-02  7.0654e-03\n",
      "  4.1878e-02 -8.1571e-03  4.1945e-02 -4.8210e-03 -2.7815e-02\n",
      " -1.1582e-03  2.5136e-02 -3.2110e-02  7.3754e-03  1.9871e-02\n",
      " -3.9835e-02  2.4917e-02 -4.5396e-02  1.3230e-02 -3.0514e-02\n",
      "  5.9232e-03  4.3769e-02  1.4302e-03  3.2920e-02 -9.9736e-03\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -5.1241e-02 -1.5696e-02  7.4439e-03 -8.8417e-03  4.2962e-02\n",
      " -1.4972e-02 -2.5163e-02 -2.9662e-02  3.8284e-02  7.4808e-03\n",
      "  2.5948e-02 -1.6416e-02 -2.5376e-02  2.9926e-02 -4.0483e-02\n",
      "  5.1247e-03  8.0549e-03 -4.5684e-02  2.1166e-02  1.2711e-02\n",
      "  1.3892e-02  3.7870e-02 -2.2903e-02 -3.2822e-02 -2.5590e-02\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -1.5602e-02 -1.1781e-02 -6.8825e-02 -2.7677e-02  1.9515e-03\n",
      "  2.7468e-02  1.5342e-02 -2.0853e-02 -4.7052e-02 -3.2813e-02\n",
      " -4.6475e-03  1.2231e-03 -2.8037e-02 -1.1930e-02  2.8643e-03\n",
      " -1.0638e-02 -1.0186e-02 -4.0811e-02 -5.0780e-02 -1.2499e-02\n",
      " -9.1305e-03  1.6420e-02  1.5648e-06  1.8433e-02 -4.5454e-02\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "  4.6107e-02 -1.1594e-03  3.4638e-02  2.3142e-02 -2.6012e-02\n",
      " -1.6468e-02 -2.4656e-02  2.3766e-02 -6.0321e-03  9.9011e-04\n",
      " -3.2779e-02 -1.9100e-02 -4.0057e-02  3.9458e-02  3.5390e-02\n",
      "  2.5601e-02 -3.1883e-02 -2.5392e-03  3.7062e-02  2.8909e-02\n",
      "  3.0079e-02 -3.5385e-03 -1.1293e-02  2.7998e-02 -1.7770e-02\n",
      "   ...\n",
      "\n",
      "(2 ,15,.,.) = \n",
      " -4.2143e-02 -3.3285e-02  2.1392e-02 -9.6084e-03 -1.7228e-02\n",
      "  1.3700e-03 -3.4945e-02 -3.2576e-02  2.1490e-02 -2.8101e-02\n",
      "  2.7193e-02  2.7431e-02 -1.2748e-02 -2.4253e-02 -2.8131e-02\n",
      " -5.4853e-03 -3.9141e-02 -2.8451e-02 -2.0048e-02 -2.7547e-02\n",
      "  1.5633e-03  3.9538e-02  2.6559e-02  3.0977e-02  2.7168e-02\n",
      "\n",
      "(2 ,16,.,.) = \n",
      "  2.9056e-02 -1.4245e-02  1.8452e-02  1.8498e-02  1.3836e-02\n",
      " -1.2916e-02  5.4586e-04  2.5587e-02 -1.0111e-03 -3.3407e-02\n",
      "  1.3632e-02 -3.6562e-02  1.8214e-02 -4.2081e-02 -4.0562e-02\n",
      "  1.7080e-02 -2.4278e-03 -2.8892e-02 -1.7215e-02 -1.7831e-02\n",
      " -4.9353e-02  3.7777e-03  1.7639e-02 -4.6034e-02  3.5182e-02\n",
      "\n",
      "(2 ,17,.,.) = \n",
      "  2.9554e-02 -2.2084e-02 -1.2072e-02 -6.9035e-03  1.8674e-02\n",
      "  2.6071e-02 -2.7519e-02 -2.6649e-02  1.7147e-02  3.2473e-03\n",
      " -2.7985e-03 -1.3413e-02  2.6030e-02  3.1728e-02 -4.0289e-02\n",
      " -3.3926e-02 -4.2268e-02 -3.1024e-02  1.9492e-02 -2.8803e-02\n",
      " -2.2619e-02  3.2524e-02 -1.2309e-03  1.1849e-02  3.1313e-02\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(24,0 ,.,.) = \n",
      " -8.3179e-03  1.6606e-02 -1.4046e-02 -1.4256e-02 -4.2449e-02\n",
      "  6.1720e-03  4.3670e-02  4.8672e-02  9.1957e-03 -9.8422e-03\n",
      " -3.3664e-02  7.9349e-03 -1.9398e-02 -1.7430e-02  9.2770e-03\n",
      "  9.1551e-03 -4.2505e-03  1.8560e-02  1.6113e-02 -3.4454e-02\n",
      " -3.9166e-02  3.2942e-02  4.3059e-03  4.5129e-02 -5.2094e-03\n",
      "\n",
      "(24,1 ,.,.) = \n",
      " -9.0948e-03  1.6620e-02 -1.7768e-02  2.6421e-02 -3.7558e-02\n",
      " -6.2534e-02  1.6820e-03 -4.1190e-02  1.2191e-02  1.5649e-02\n",
      " -5.3355e-02 -2.4218e-02 -4.6424e-02  2.0843e-02  3.3479e-02\n",
      "  5.7402e-03 -4.6516e-03 -9.6814e-03 -1.5517e-02  1.8931e-02\n",
      "  1.0490e-02  1.6491e-02 -3.9734e-02 -2.4290e-02  6.0059e-03\n",
      "\n",
      "(24,2 ,.,.) = \n",
      "  2.1886e-02 -1.8377e-03  2.9982e-02 -4.4989e-02  2.3573e-02\n",
      "  3.4472e-03  1.1077e-02  3.8228e-03  4.8412e-02  3.1441e-02\n",
      "  3.1276e-02 -4.3627e-02  4.2334e-03  4.2748e-03  2.2142e-02\n",
      " -1.3148e-02  1.3504e-02 -3.9068e-02  2.1512e-02 -3.1346e-02\n",
      " -2.8198e-02  1.5280e-02  4.0031e-02 -1.0216e-02 -2.3619e-02\n",
      "   ...\n",
      "\n",
      "(24,15,.,.) = \n",
      "  1.8726e-02 -1.5301e-02  5.7728e-03 -2.4109e-02  6.7195e-03\n",
      " -1.8951e-02  2.6227e-02 -4.0886e-02  4.3339e-02  1.3864e-02\n",
      " -3.0653e-02  1.5477e-02  3.5293e-02  1.8392e-03 -3.7390e-02\n",
      " -2.2689e-02  3.1560e-02  4.4556e-02 -2.8166e-02  3.5772e-02\n",
      "  4.0437e-02  3.6411e-02 -2.0727e-02 -2.0584e-02  2.0786e-02\n",
      "\n",
      "(24,16,.,.) = \n",
      "  4.3993e-02 -3.6390e-02 -2.0692e-02  1.3406e-02 -1.1805e-02\n",
      " -4.0276e-02 -3.7468e-02  1.8532e-02 -4.2957e-02  1.2654e-02\n",
      "  3.1727e-02  2.0103e-03 -3.2302e-02  2.4241e-02 -3.2300e-02\n",
      "  3.6770e-02 -2.5656e-02 -2.4310e-02 -3.9962e-02  7.1296e-03\n",
      "  2.3117e-02  2.3229e-02  3.8626e-02 -3.7744e-02 -6.1430e-03\n",
      "\n",
      "(24,17,.,.) = \n",
      "  1.1829e-02 -1.6470e-02 -3.1947e-02 -1.7191e-02 -3.2344e-02\n",
      " -1.1654e-02  4.3355e-04 -4.2397e-02 -7.0470e-03 -2.6864e-02\n",
      "  5.8956e-03 -4.5088e-02 -3.6739e-02 -1.9867e-02  9.4725e-03\n",
      "  1.8231e-02 -2.9964e-02 -6.2230e-03  2.0151e-02  4.3730e-02\n",
      "  2.5207e-02  1.7574e-02  1.0264e-02 -4.4104e-02 -1.4614e-02\n",
      "     ⋮ \n",
      "\n",
      "(25,0 ,.,.) = \n",
      " -3.5555e-02 -3.1671e-02 -2.8163e-02  5.8641e-02 -4.4502e-03\n",
      " -1.8565e-02 -1.0629e-04 -3.1688e-02 -2.1328e-02 -2.5681e-03\n",
      " -5.3915e-02 -7.6776e-02  7.1297e-03 -1.3984e-02  3.9653e-02\n",
      " -3.3485e-02  1.6391e-02 -3.9490e-02 -1.1413e-02 -3.1656e-02\n",
      " -6.0445e-02 -5.5259e-02  1.1882e-02 -5.1167e-02  5.0860e-03\n",
      "\n",
      "(25,1 ,.,.) = \n",
      " -2.5936e-02  2.5425e-03 -2.1659e-02 -1.1041e-03 -3.0383e-03\n",
      "  7.0953e-03 -4.7438e-02 -1.1779e-03 -1.0841e-02 -1.2246e-03\n",
      " -5.1871e-02  5.0342e-03 -1.4308e-02  2.6971e-02  7.0585e-02\n",
      " -5.4637e-02 -6.1612e-02  2.3423e-02  2.9987e-02  7.3440e-02\n",
      " -1.5864e-02 -6.4347e-02 -1.7698e-02  7.3911e-02  2.3192e-02\n",
      "\n",
      "(25,2 ,.,.) = \n",
      " -4.3637e-02  2.7034e-02  3.2076e-02 -2.6152e-02  2.3025e-02\n",
      "  4.2604e-02 -1.9093e-05 -5.2647e-03  2.2206e-02  1.1094e-02\n",
      " -1.3050e-03  1.5596e-02 -2.2838e-02  2.3924e-02  3.4342e-02\n",
      " -2.9941e-03 -6.7635e-03 -1.1904e-02 -1.1546e-02 -3.5174e-02\n",
      " -2.6443e-02  7.7113e-03 -2.4538e-02 -1.2600e-02 -1.3486e-02\n",
      "   ...\n",
      "\n",
      "(25,15,.,.) = \n",
      " -1.2481e-02  1.9892e-02  4.1339e-02  2.7771e-02  8.1704e-03\n",
      "  3.4455e-02  4.0164e-02 -3.9403e-02 -4.9691e-02  2.4906e-03\n",
      "  1.2291e-02 -3.1420e-02  9.3344e-03  3.5155e-02  3.4274e-02\n",
      "  2.8267e-02 -5.0774e-02 -2.2255e-02 -3.2301e-02 -3.0290e-02\n",
      " -1.8887e-02  1.5292e-02  2.6372e-02  2.5430e-02 -2.9569e-02\n",
      "\n",
      "(25,16,.,.) = \n",
      " -7.2496e-03  3.1437e-02  3.0358e-02 -1.4338e-02  1.3669e-03\n",
      " -4.4776e-02 -2.5285e-02 -3.7091e-02 -2.0757e-02 -3.3030e-02\n",
      " -5.3167e-02  1.2101e-02 -1.6591e-02 -4.1548e-02  2.1620e-02\n",
      " -4.5831e-02 -6.9180e-02  1.3125e-02 -5.0746e-02 -3.9084e-02\n",
      " -4.5697e-02 -2.2101e-02 -3.5609e-02 -1.3329e-02  1.6402e-02\n",
      "\n",
      "(25,17,.,.) = \n",
      "  2.3593e-02 -4.9175e-03 -2.7298e-02 -1.2668e-02 -8.5195e-03\n",
      " -3.6135e-02 -2.9711e-02  2.4325e-02  1.1697e-02  2.3903e-02\n",
      " -3.9965e-02 -2.2634e-02 -8.1258e-03  1.4902e-02  1.7200e-02\n",
      "  4.5481e-02  4.1754e-02  4.5369e-02  4.3926e-02 -4.0579e-02\n",
      " -4.2524e-03 -2.0671e-02 -2.6509e-03  3.6123e-02  1.9314e-02\n",
      "     ⋮ \n",
      "\n",
      "(26,0 ,.,.) = \n",
      "  3.1520e-02 -3.2808e-02 -4.0461e-02 -2.3348e-02  3.8790e-02\n",
      " -1.4898e-02  3.3361e-03 -4.0325e-02 -7.0672e-03  1.6089e-02\n",
      "  9.8965e-03  1.0748e-02 -3.4290e-03  2.2423e-02  4.4079e-02\n",
      " -3.3137e-02 -1.6018e-02 -8.1616e-03  4.0229e-02 -8.2356e-03\n",
      "  2.2432e-02  1.3426e-02 -4.5635e-02  2.5416e-02  5.6160e-02\n",
      "\n",
      "(26,1 ,.,.) = \n",
      " -2.3059e-02 -4.2672e-05 -3.6272e-02 -2.0066e-02 -4.6842e-02\n",
      " -9.2339e-03  2.0489e-02  4.3882e-03  4.6921e-03  1.9120e-02\n",
      " -3.5493e-02 -2.3290e-02 -1.8283e-02 -1.3476e-02  1.0466e-02\n",
      "  3.4608e-02  3.8839e-02  4.3020e-02  1.0698e-02 -5.5340e-02\n",
      " -1.0454e-02 -3.8866e-02  3.4066e-02 -1.4662e-02  7.6065e-03\n",
      "\n",
      "(26,2 ,.,.) = \n",
      "  2.1326e-02  2.4740e-03  1.3442e-02 -4.5931e-02  1.6582e-02\n",
      " -3.7510e-02  5.7583e-04 -4.5059e-02  2.8287e-02 -2.9823e-02\n",
      "  2.3395e-02  3.5902e-02 -4.7938e-02  8.6980e-03 -2.6036e-02\n",
      " -2.3295e-02  2.0630e-02  3.1486e-02  3.5312e-02 -4.6810e-02\n",
      "  1.6331e-02  3.1074e-02  3.7732e-02  1.1262e-02 -2.0651e-02\n",
      "   ...\n",
      "\n",
      "(26,15,.,.) = \n",
      " -4.2311e-02  1.8693e-02  3.3501e-02  4.6118e-03  7.9208e-03\n",
      " -7.9046e-03  2.3647e-02  4.1726e-02  6.8641e-03  3.9951e-02\n",
      "  1.2852e-02 -8.9089e-03 -1.1710e-02  3.5850e-02 -1.2580e-02\n",
      " -4.8484e-02  1.2392e-02  2.0962e-02  1.2873e-02 -4.1651e-02\n",
      "  6.2402e-03  7.8880e-03 -2.1882e-03  2.1669e-02 -5.6897e-03\n",
      "\n",
      "(26,16,.,.) = \n",
      " -2.1580e-02 -3.1221e-02  6.6046e-03  1.3909e-02  4.6623e-03\n",
      " -4.1452e-02 -3.9854e-02 -2.6923e-02  5.1150e-02 -3.0985e-02\n",
      "  1.0860e-02 -3.5095e-02  4.7068e-02  4.7049e-02  5.0459e-02\n",
      "  1.2752e-02  1.4242e-02  2.4709e-02 -3.7555e-02  2.3393e-02\n",
      " -1.0674e-02 -1.9885e-02 -4.3161e-02  3.8669e-02 -3.9446e-03\n",
      "\n",
      "(26,17,.,.) = \n",
      " -5.9295e-03 -4.2270e-02  1.4426e-02  4.4415e-03  4.6877e-02\n",
      " -2.9537e-02  2.1685e-02 -3.0442e-02 -3.9720e-02  2.5222e-02\n",
      " -4.4594e-02 -4.8443e-03 -5.0796e-03  7.7175e-03  4.8106e-02\n",
      "  1.7000e-03 -4.4995e-02  2.7033e-03 -3.5481e-02  2.6925e-02\n",
      "  4.0184e-02  8.6859e-03 -1.4914e-02  3.5236e-02 -1.8747e-02\n",
      "[torch.cuda.DoubleTensor of size 27x18x5x5 (GPU 0)]\n",
      "), ('conv3.bias', \n",
      "-0.0501\n",
      "-0.0063\n",
      "-0.0417\n",
      "-0.0315\n",
      "-0.0836\n",
      " 0.4008\n",
      "-0.0418\n",
      "-0.1043\n",
      "-0.0025\n",
      "-0.0121\n",
      " 0.2851\n",
      "-0.0356\n",
      "-0.0280\n",
      " 0.0035\n",
      "-0.0283\n",
      "-0.0200\n",
      "-0.0774\n",
      "-0.1639\n",
      " 0.0078\n",
      "-0.0349\n",
      "-0.0007\n",
      " 0.5595\n",
      "-0.0352\n",
      "-0.0858\n",
      "-0.0664\n",
      " 0.1601\n",
      "-0.0129\n",
      "[torch.cuda.DoubleTensor of size 27 (GPU 0)]\n",
      "), ('fc1.weight', \n",
      " 6.1531e-03 -2.5320e-03 -3.8418e-03  ...   8.0393e-03 -5.6360e-03  5.8841e-03\n",
      " 6.6106e-03  1.4230e-03  3.2984e-03  ...   7.4228e-04  2.4300e-03  6.1749e-03\n",
      " 5.9962e-03 -4.9440e-03 -3.1186e-03  ...   3.1811e-03  5.2952e-04 -4.3035e-03\n",
      "                ...                   ⋱                   ...                \n",
      "-3.4738e-03  1.2167e-04  4.4644e-03  ...  -5.5054e-03  5.7791e-03  5.4492e-03\n",
      "-9.3619e-03  1.2792e-04 -5.9809e-03  ...  -9.3268e-03  4.1028e-04 -6.3826e-03\n",
      "-6.0586e-03  8.2659e-03  6.5563e-03  ...  -2.0378e-03  3.5869e-03 -5.2371e-03\n",
      "[torch.cuda.DoubleTensor of size 512x15147 (GPU 0)]\n",
      "), ('fc1.bias', \n",
      "1.00000e-02 *\n",
      "  0.0178\n",
      "  0.4364\n",
      " -0.2638\n",
      "  1.0600\n",
      " -1.3728\n",
      "  0.3931\n",
      " -0.7839\n",
      " -0.6705\n",
      " -0.6269\n",
      "  0.8421\n",
      " -1.1196\n",
      " -0.4542\n",
      " -0.1310\n",
      "  2.0042\n",
      "  0.9321\n",
      "  1.8460\n",
      "  0.2039\n",
      " -0.0081\n",
      "  0.1242\n",
      "  2.8835\n",
      " -0.6542\n",
      "  1.9967\n",
      " -0.5072\n",
      "  2.4906\n",
      "  0.9818\n",
      " -0.9424\n",
      "  1.5684\n",
      "  1.1359\n",
      " -0.3724\n",
      " -1.0521\n",
      "  0.8376\n",
      " -0.2672\n",
      "  0.4265\n",
      "  0.3774\n",
      " -1.0839\n",
      "  0.8853\n",
      "  0.1944\n",
      "  1.8299\n",
      "  0.5777\n",
      " -0.6818\n",
      "  0.7824\n",
      "  1.3039\n",
      "  1.5501\n",
      "  0.8479\n",
      "  0.0194\n",
      " -1.1266\n",
      " -0.6605\n",
      "  0.1362\n",
      "  0.5390\n",
      " -0.2216\n",
      " -0.8455\n",
      "  0.7392\n",
      " -1.0189\n",
      " -0.2682\n",
      "  0.1877\n",
      "  0.2058\n",
      "  0.1461\n",
      "  0.4453\n",
      " -0.2730\n",
      "  0.9328\n",
      " -0.1761\n",
      "  0.3421\n",
      " -1.1795\n",
      "  0.0828\n",
      " -0.3375\n",
      "  0.1876\n",
      " -0.0664\n",
      "  0.2294\n",
      " -0.1812\n",
      "  0.3224\n",
      "  1.3819\n",
      " -0.3993\n",
      "  0.1579\n",
      " -0.5651\n",
      " -0.5970\n",
      "  0.0475\n",
      " -0.5112\n",
      " -0.8799\n",
      "  0.0764\n",
      "  1.6231\n",
      " -0.9249\n",
      "  2.0178\n",
      "  1.0539\n",
      "  0.5995\n",
      " -0.6088\n",
      "  1.4250\n",
      " -0.9126\n",
      "  1.1771\n",
      "  0.2090\n",
      " -0.0800\n",
      " -0.0757\n",
      " -0.2534\n",
      "  0.6961\n",
      " -0.6749\n",
      "  0.2482\n",
      "  2.1496\n",
      " -0.3134\n",
      " -0.5122\n",
      " -0.6272\n",
      "  0.6355\n",
      " -0.2779\n",
      " -0.3934\n",
      " -0.0471\n",
      "  3.9304\n",
      "  0.2323\n",
      "  0.0658\n",
      "  0.0292\n",
      "  0.3306\n",
      " -0.7052\n",
      " -0.5264\n",
      "  0.6610\n",
      " -0.6051\n",
      " -0.4630\n",
      "  0.5773\n",
      "  1.5761\n",
      " -0.9816\n",
      " -0.5994\n",
      "  0.7161\n",
      " -0.0242\n",
      "  2.0475\n",
      " -0.7088\n",
      "  0.4402\n",
      " -0.0074\n",
      "  1.2038\n",
      "  0.3735\n",
      "  0.4244\n",
      "  0.3249\n",
      "  0.0512\n",
      "  1.5117\n",
      " -1.0280\n",
      "  3.5879\n",
      " -0.8381\n",
      "  0.4802\n",
      " -0.5942\n",
      " -0.4416\n",
      "  0.0537\n",
      " -0.6114\n",
      " -1.2576\n",
      " -0.0554\n",
      " -1.0213\n",
      " -1.5930\n",
      "  1.2422\n",
      " -0.4732\n",
      " -0.0591\n",
      " -0.1625\n",
      " -2.0066\n",
      " -0.7791\n",
      " -0.0625\n",
      " -1.0218\n",
      " -0.7836\n",
      "  1.4026\n",
      " -1.0399\n",
      " -0.1858\n",
      "  0.8125\n",
      " -1.1913\n",
      " -0.2297\n",
      "  2.1384\n",
      " -0.5352\n",
      " -1.2135\n",
      "  0.8290\n",
      " -0.2046\n",
      " -0.5964\n",
      " -0.4237\n",
      " -0.5312\n",
      "  0.0069\n",
      " -1.4459\n",
      " -0.2923\n",
      "  0.6351\n",
      " -1.0777\n",
      "  0.9099\n",
      "  0.1144\n",
      "  1.1218\n",
      " -0.0512\n",
      " -0.4602\n",
      "  0.0940\n",
      " -1.0683\n",
      "  2.2553\n",
      "  1.0243\n",
      " -0.9923\n",
      "  0.7564\n",
      "  1.2825\n",
      "  0.2534\n",
      " -0.0759\n",
      " -0.5575\n",
      "  1.1927\n",
      " -0.8671\n",
      "  0.1426\n",
      " -0.8131\n",
      " -1.4234\n",
      "  2.5002\n",
      " -1.8869\n",
      "  1.8868\n",
      "  0.4014\n",
      " -1.0126\n",
      " -0.7744\n",
      "  0.0189\n",
      " -1.0424\n",
      " -0.2138\n",
      " -1.1179\n",
      " -0.0466\n",
      " -0.5286\n",
      " -0.4933\n",
      " -0.2610\n",
      "  3.3124\n",
      "  1.3028\n",
      "  1.0518\n",
      " -0.8026\n",
      " -0.6568\n",
      "  0.9793\n",
      " -1.1066\n",
      "  1.4808\n",
      " -0.8667\n",
      "  0.7733\n",
      " -1.4240\n",
      " -1.8279\n",
      "  2.9252\n",
      " -0.5554\n",
      " -0.6535\n",
      " -1.0476\n",
      " -0.8896\n",
      "  1.9257\n",
      "  0.1490\n",
      "  1.3412\n",
      "  0.9585\n",
      " -0.1807\n",
      "  0.6344\n",
      "  0.0730\n",
      " -0.4315\n",
      " -1.1819\n",
      " -0.4897\n",
      " -1.1856\n",
      " -0.1683\n",
      "  0.8314\n",
      "  0.2359\n",
      " -0.7099\n",
      " -0.8158\n",
      "  0.5053\n",
      "  1.9950\n",
      "  1.0221\n",
      " -0.0192\n",
      "  0.2404\n",
      " -0.2530\n",
      " -1.3432\n",
      "  0.7241\n",
      " -0.3962\n",
      "  0.2373\n",
      "  0.3069\n",
      " -0.8181\n",
      " -0.2019\n",
      "  0.3443\n",
      "  0.3771\n",
      "  0.1848\n",
      " -0.5339\n",
      "  0.8547\n",
      " -1.0574\n",
      " -0.7696\n",
      " -0.4450\n",
      "  1.4606\n",
      "  0.3197\n",
      "  1.0317\n",
      "  0.4638\n",
      "  0.4840\n",
      " -1.1746\n",
      " -0.5062\n",
      " -0.3282\n",
      "  0.0881\n",
      " -1.6210\n",
      " -0.0394\n",
      " -0.0424\n",
      " -0.2791\n",
      "  3.3974\n",
      "  1.2376\n",
      " -0.4451\n",
      " -0.6716\n",
      "  0.8001\n",
      " -0.7698\n",
      " -0.0871\n",
      " -0.0550\n",
      " -0.6572\n",
      " -1.7361\n",
      "  0.2222\n",
      " -0.3543\n",
      " -0.9850\n",
      " -0.4671\n",
      "  0.2617\n",
      "  0.1576\n",
      " -1.1246\n",
      "  0.7024\n",
      " -0.9265\n",
      " -1.2132\n",
      "  2.0957\n",
      "  0.1262\n",
      " -0.8957\n",
      " -0.7329\n",
      " -0.9512\n",
      "  0.0074\n",
      "  0.1806\n",
      "  1.0519\n",
      " -0.6293\n",
      " -1.3456\n",
      " -0.9753\n",
      " -0.1877\n",
      " -0.2982\n",
      "  0.1268\n",
      " -0.6428\n",
      " -0.6327\n",
      "  0.4612\n",
      "  0.1166\n",
      " -0.6509\n",
      " -0.0768\n",
      "  1.2465\n",
      "  1.7836\n",
      "  0.7607\n",
      " -0.7674\n",
      "  1.0468\n",
      " -0.3003\n",
      "  0.5032\n",
      " -0.3338\n",
      "  1.3308\n",
      "  0.1137\n",
      "  1.3908\n",
      " -1.1126\n",
      "  0.1149\n",
      " -0.8714\n",
      "  0.2061\n",
      " -0.1278\n",
      " -0.5101\n",
      "  0.0074\n",
      " -1.2702\n",
      "  0.1986\n",
      " -0.1310\n",
      "  0.6108\n",
      " -0.4724\n",
      "  1.0202\n",
      "  1.5351\n",
      " -0.7433\n",
      " -0.2919\n",
      "  1.6963\n",
      " -1.1624\n",
      " -0.0100\n",
      " -0.3705\n",
      " -0.2323\n",
      " -0.6427\n",
      "  0.3797\n",
      "  0.9041\n",
      " -0.5728\n",
      " -0.1302\n",
      " -0.7006\n",
      "  0.9611\n",
      " -1.1545\n",
      " -1.8994\n",
      " -0.9614\n",
      "  0.2473\n",
      " -1.0493\n",
      " -0.6502\n",
      "  0.5084\n",
      "  0.7472\n",
      " -0.2702\n",
      "  1.3844\n",
      "  1.1111\n",
      " -0.5040\n",
      "  0.9396\n",
      "  0.1091\n",
      " -0.4581\n",
      "  1.9306\n",
      " -1.6416\n",
      " -0.7565\n",
      " -1.2452\n",
      " -0.3010\n",
      " -0.4244\n",
      "  0.1858\n",
      "  0.1660\n",
      "  0.6045\n",
      "  0.2825\n",
      " -0.9352\n",
      " -1.0883\n",
      " -1.4242\n",
      " -0.8686\n",
      " -1.3148\n",
      "  1.6578\n",
      " -0.4364\n",
      " -0.2240\n",
      " -0.7072\n",
      " -0.6941\n",
      "  2.2590\n",
      "  2.0653\n",
      "  0.2479\n",
      " -0.4281\n",
      " -1.2237\n",
      " -0.7775\n",
      "  0.3864\n",
      "  0.7036\n",
      "  0.9375\n",
      "  0.1554\n",
      " -1.6585\n",
      " -1.0007\n",
      " -0.4803\n",
      " -0.5709\n",
      "  0.3464\n",
      "  0.5877\n",
      " -0.6355\n",
      " -0.8190\n",
      "  0.5481\n",
      "  2.4407\n",
      "  1.0999\n",
      " -0.2869\n",
      " -0.0477\n",
      " -0.9033\n",
      "  1.8875\n",
      " -0.3268\n",
      " -0.0286\n",
      " -0.3898\n",
      "  0.1831\n",
      " -0.5073\n",
      "  1.3038\n",
      " -0.1744\n",
      " -1.0545\n",
      " -0.6398\n",
      "  0.0217\n",
      " -1.4562\n",
      " -0.3950\n",
      "  0.5145\n",
      "  1.8374\n",
      " -0.5214\n",
      " -0.4513\n",
      " -0.3367\n",
      "  0.0089\n",
      "  0.3775\n",
      "  0.1024\n",
      "  0.7930\n",
      "  0.7339\n",
      " -0.4103\n",
      " -0.6621\n",
      "  0.3388\n",
      "  2.7720\n",
      "  0.5841\n",
      " -0.3873\n",
      "  0.1454\n",
      "  0.1281\n",
      "  2.1478\n",
      "  1.2544\n",
      " -0.2681\n",
      " -0.0829\n",
      " -0.7812\n",
      "  1.2299\n",
      " -1.2034\n",
      " -0.2275\n",
      "  0.2678\n",
      "  0.2729\n",
      " -0.1605\n",
      "  0.7298\n",
      " -0.3972\n",
      " -0.2961\n",
      " -0.7913\n",
      "  0.0468\n",
      "  0.1622\n",
      " -0.5745\n",
      "  2.0488\n",
      "  0.0214\n",
      " -0.1349\n",
      "  0.4743\n",
      "  1.2767\n",
      "  0.8248\n",
      "  1.1626\n",
      "  1.0821\n",
      " -1.4968\n",
      " -0.5991\n",
      " -1.1390\n",
      " -0.6300\n",
      " -0.4890\n",
      "  0.0918\n",
      " -0.2212\n",
      " -0.4489\n",
      "  0.3539\n",
      " -0.3389\n",
      "  0.0051\n",
      " -0.4120\n",
      " -0.4612\n",
      "  0.2955\n",
      "  0.7671\n",
      "  0.0104\n",
      " -0.2574\n",
      " -0.1400\n",
      " -0.0081\n",
      "  0.0056\n",
      "  0.3590\n",
      "  0.9727\n",
      " -1.1821\n",
      " -0.3954\n",
      "  1.5937\n",
      " -0.3084\n",
      " -0.0195\n",
      " -0.2015\n",
      " -0.2701\n",
      " -1.1403\n",
      " -0.9185\n",
      " -0.2085\n",
      " -0.9094\n",
      "  1.1409\n",
      " -0.2625\n",
      " -0.2039\n",
      " -0.7562\n",
      "  0.8915\n",
      "  2.0373\n",
      " -0.6136\n",
      "  2.8818\n",
      "  0.0976\n",
      " -0.0814\n",
      "  0.8496\n",
      "  1.7222\n",
      "  0.6359\n",
      "  0.0885\n",
      "[torch.cuda.DoubleTensor of size 512 (GPU 0)]\n",
      "), ('fc2.weight', \n",
      "1.00000e-02 *\n",
      "-1.9318 -2.9151  0.4775  ...   1.1138  3.4580 -3.3272\n",
      " 2.3246 -2.5432 -0.6484  ...  -2.7087  3.9702  2.2579\n",
      " 1.9847 -2.4701  2.4995  ...  -0.7050  2.6260 -3.6981\n",
      "          ...             ⋱             ...          \n",
      "-2.0124 -1.2838  3.7301  ...  -1.4326  2.6884 -2.6246\n",
      " 4.0823  2.0104  0.5027  ...  -1.9508 -0.5633 -4.0329\n",
      " 1.1019 -2.4792 -0.0353  ...   0.3143  0.8975 -1.9483\n",
      "[torch.cuda.DoubleTensor of size 256x512 (GPU 0)]\n",
      "), ('fc2.bias', \n",
      "-0.0348\n",
      "-0.0003\n",
      "-0.0201\n",
      "-0.0317\n",
      "-0.0503\n",
      "-0.0429\n",
      "-0.0402\n",
      " 0.1259\n",
      " 0.0130\n",
      "-0.0324\n",
      " 0.0266\n",
      "-0.0176\n",
      " 0.0309\n",
      "-0.0419\n",
      "-0.0255\n",
      "-0.0746\n",
      "-0.0284\n",
      "-0.0258\n",
      " 0.0002\n",
      "-0.0072\n",
      " 0.0339\n",
      " 0.0503\n",
      " 0.0052\n",
      "-0.0124\n",
      "-0.0580\n",
      "-0.0279\n",
      " 0.0059\n",
      "-0.0619\n",
      "-0.0342\n",
      " 0.0155\n",
      "-0.0296\n",
      " 0.0282\n",
      "-0.0284\n",
      " 0.0248\n",
      " 0.0310\n",
      "-0.0282\n",
      "-0.0264\n",
      "-0.0319\n",
      " 0.0249\n",
      "-0.0448\n",
      " 0.0136\n",
      "-0.0876\n",
      " 0.0917\n",
      "-0.0616\n",
      "-0.0252\n",
      "-0.0236\n",
      " 0.0007\n",
      " 0.0146\n",
      "-0.0307\n",
      "-0.0453\n",
      "-0.0215\n",
      " 0.0089\n",
      " 0.1249\n",
      "-0.0022\n",
      " 0.0080\n",
      " 0.0408\n",
      " 0.0571\n",
      " 0.0820\n",
      "-0.0060\n",
      " 0.0146\n",
      "-0.0160\n",
      "-0.0209\n",
      " 0.0331\n",
      "-0.0229\n",
      "-0.0148\n",
      "-0.0521\n",
      " 0.0132\n",
      " 0.1456\n",
      "-0.0397\n",
      " 0.0404\n",
      "-0.0872\n",
      "-0.0113\n",
      "-0.0228\n",
      " 0.0061\n",
      " 0.0406\n",
      "-0.0404\n",
      " 0.0195\n",
      " 0.0117\n",
      "-0.0574\n",
      " 0.0322\n",
      " 0.0023\n",
      "-0.0292\n",
      " 0.0096\n",
      " 0.0259\n",
      "-0.0146\n",
      "-0.0339\n",
      "-0.0595\n",
      "-0.0089\n",
      " 0.0148\n",
      " 0.0588\n",
      "-0.0160\n",
      " 0.0054\n",
      " 0.0309\n",
      " 0.0488\n",
      "-0.0378\n",
      "-0.0508\n",
      "-0.0592\n",
      "-0.0404\n",
      " 0.0144\n",
      "-0.0299\n",
      "-0.0130\n",
      "-0.0401\n",
      "-0.0009\n",
      "-0.0183\n",
      "-0.0398\n",
      " 0.0369\n",
      "-0.0461\n",
      "-0.0125\n",
      "-0.0128\n",
      "-0.0434\n",
      "-0.0398\n",
      "-0.0124\n",
      "-0.0629\n",
      "-0.0139\n",
      "-0.0163\n",
      " 0.0081\n",
      "-0.0136\n",
      " 0.0137\n",
      " 0.0174\n",
      "-0.0431\n",
      " 0.0346\n",
      " 0.0320\n",
      " 0.0332\n",
      "-0.0313\n",
      "-0.0093\n",
      " 0.0856\n",
      "-0.0273\n",
      " 0.0790\n",
      "-0.0169\n",
      "-0.0506\n",
      " 0.0761\n",
      "-0.0323\n",
      "-0.0343\n",
      " 0.0397\n",
      " 0.0487\n",
      " 0.0346\n",
      "-0.0006\n",
      "-0.0278\n",
      " 0.0824\n",
      " 0.0280\n",
      " 0.0340\n",
      "-0.0338\n",
      "-0.0244\n",
      " 0.1124\n",
      " 0.0649\n",
      " 0.0390\n",
      " 0.0707\n",
      "-0.0025\n",
      "-0.0060\n",
      "-0.0517\n",
      "-0.0332\n",
      " 0.2614\n",
      "-0.0193\n",
      " 0.0226\n",
      " 0.0550\n",
      " 0.0358\n",
      " 0.1374\n",
      " 0.0045\n",
      "-0.0016\n",
      "-0.0450\n",
      " 0.0164\n",
      "-0.0458\n",
      "-0.0031\n",
      "-0.0160\n",
      "-0.0334\n",
      "-0.0065\n",
      "-0.0267\n",
      " 0.0068\n",
      " 0.0167\n",
      "-0.0023\n",
      " 0.0009\n",
      " 0.0295\n",
      "-0.0054\n",
      "-0.0140\n",
      "-0.0117\n",
      " 0.0840\n",
      " 0.0961\n",
      "-0.0000\n",
      "-0.0150\n",
      " 0.0080\n",
      " 0.0955\n",
      "-0.0091\n",
      "-0.0254\n",
      " 0.0184\n",
      " 0.0652\n",
      "-0.0070\n",
      " 0.0118\n",
      "-0.0236\n",
      "-0.0219\n",
      " 0.0315\n",
      " 0.0381\n",
      "-0.0345\n",
      " 0.0443\n",
      " 0.0452\n",
      " 0.0155\n",
      "-0.0297\n",
      "-0.0209\n",
      "-0.0259\n",
      " 0.0335\n",
      " 0.0181\n",
      "-0.0314\n",
      " 0.0206\n",
      " 0.0023\n",
      " 0.0262\n",
      " 0.0842\n",
      "-0.0503\n",
      "-0.0033\n",
      " 0.0644\n",
      "-0.0180\n",
      "-0.1056\n",
      "-0.0399\n",
      "-0.0101\n",
      " 0.0091\n",
      "-0.0006\n",
      "-0.0147\n",
      " 0.0154\n",
      "-0.0616\n",
      "-0.0162\n",
      " 0.0511\n",
      " 0.0099\n",
      "-0.0311\n",
      "-0.0294\n",
      "-0.0233\n",
      " 0.0251\n",
      " 0.0117\n",
      "-0.0293\n",
      "-0.0216\n",
      " 0.0068\n",
      "-0.0292\n",
      " 0.0013\n",
      " 0.0443\n",
      "-0.0638\n",
      "-0.0056\n",
      "-0.0131\n",
      "-0.0318\n",
      "-0.0052\n",
      "-0.0728\n",
      "-0.0225\n",
      " 0.0988\n",
      " 0.0052\n",
      " 0.0172\n",
      "-0.0048\n",
      "-0.0087\n",
      "-0.0071\n",
      "-0.0285\n",
      "-0.0356\n",
      " 0.0122\n",
      "-0.0317\n",
      "-0.0299\n",
      "-0.0034\n",
      "-0.0224\n",
      "-0.0302\n",
      " 0.0148\n",
      "-0.0189\n",
      " 0.0179\n",
      "-0.0141\n",
      "[torch.cuda.DoubleTensor of size 256 (GPU 0)]\n",
      "), ('fc3.weight', \n",
      " 3.0855e-02 -5.5535e-02  7.5434e-03  ...   1.8800e-02 -2.1272e-02 -3.1728e-02\n",
      " 4.0776e-02  6.1574e-02 -6.2645e-03  ...  -5.6541e-03  2.9063e-02  4.0600e-02\n",
      "-1.1536e-02  4.7689e-02 -9.0239e-03  ...   4.0275e-02 -6.0445e-02  4.3168e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-5.1993e-02 -6.2519e-02  4.8917e-02  ...  -8.0555e-03 -8.4624e-03  4.4607e-02\n",
      " 4.6383e-02 -9.3982e-03 -5.6343e-02  ...   4.3094e-02 -5.7433e-02 -4.2168e-02\n",
      "-2.6975e-02  9.8884e-03 -2.7294e-02  ...  -5.3639e-02 -5.3939e-02 -3.2462e-02\n",
      "[torch.cuda.DoubleTensor of size 104x256 (GPU 0)]\n",
      "), ('fc3.bias', \n",
      " 0.2746\n",
      "-0.0556\n",
      " 0.0139\n",
      " 0.0567\n",
      " 0.4041\n",
      "-0.0311\n",
      "-0.0315\n",
      "-0.0137\n",
      "-0.0598\n",
      " 0.4071\n",
      " 0.1179\n",
      "-0.0645\n",
      " 0.0300\n",
      "-0.0215\n",
      " 0.0371\n",
      "-0.0035\n",
      "-0.0306\n",
      " 0.0223\n",
      "-0.0361\n",
      "-0.0586\n",
      "-0.0095\n",
      " 0.0134\n",
      " 0.0234\n",
      " 0.0311\n",
      "-0.0160\n",
      "-0.0324\n",
      " 0.0260\n",
      "-0.0198\n",
      "-0.0005\n",
      "-0.0135\n",
      "-0.0238\n",
      " 0.2206\n",
      "-0.0441\n",
      "-0.1219\n",
      "-0.0595\n",
      "-0.0096\n",
      "-0.0246\n",
      "-0.0474\n",
      " 0.0185\n",
      "-0.0052\n",
      " 0.0189\n",
      "-0.0718\n",
      "-0.0508\n",
      " 0.0570\n",
      " 0.4072\n",
      "-0.0206\n",
      " 0.0123\n",
      " 0.0215\n",
      "-0.0168\n",
      " 0.0843\n",
      "-0.0550\n",
      " 0.0117\n",
      " 0.0079\n",
      "-0.0245\n",
      "-0.0834\n",
      "-0.0632\n",
      "-0.0157\n",
      "-0.0002\n",
      "-0.0534\n",
      "-0.0324\n",
      "-0.0465\n",
      " 0.0178\n",
      " 0.0506\n",
      " 0.3325\n",
      " 0.0362\n",
      " 0.0239\n",
      "-0.0047\n",
      "-0.0554\n",
      "-0.0648\n",
      "-0.0922\n",
      "-0.0931\n",
      "-0.0610\n",
      " 0.0457\n",
      " 0.0074\n",
      " 0.2353\n",
      " 0.0058\n",
      "-0.0350\n",
      " 0.0949\n",
      " 0.4105\n",
      " 0.0352\n",
      " 0.0201\n",
      "-0.0510\n",
      " 0.1472\n",
      "-0.0571\n",
      " 0.0214\n",
      " 0.0544\n",
      "-0.0498\n",
      "-0.0832\n",
      "-0.0761\n",
      "-0.0716\n",
      " 0.3195\n",
      " 0.0188\n",
      "-0.0134\n",
      " 0.4900\n",
      " 0.3613\n",
      " 0.0133\n",
      "-0.0271\n",
      " 0.0931\n",
      " 0.0127\n",
      " 0.0204\n",
      " 0.0363\n",
      " 0.1131\n",
      "-0.0587\n",
      "-0.0987\n",
      "[torch.cuda.DoubleTensor of size 104 (GPU 0)]\n",
      "), ('fc4.weight', \n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.1549 -0.0400  0.0163  0.1014 -0.2286 -0.0460 -0.0487 -0.0503 -0.0417 -0.2301\n",
      " 0.2061  0.0279 -0.0621 -0.0854  0.2061 -0.1075 -0.0295 -0.0435 -0.0666  0.1961\n",
      "\n",
      "Columns 10 to 19 \n",
      "-0.0473  0.0137  0.0557 -0.0252  0.0451 -0.1063 -0.0739  0.0295 -0.0446  0.0274\n",
      " 0.1020 -0.0734 -0.0745 -0.0250 -0.0917 -0.0642 -0.0871 -0.0792 -0.0136 -0.0392\n",
      "\n",
      "Columns 20 to 29 \n",
      "-0.0407  0.1171  0.0483  0.0336 -0.0637  0.0678  0.0857  0.0001  0.0324 -0.0094\n",
      " 0.0704 -0.0017  0.0728  0.0666 -0.0625  0.0238 -0.0741 -0.0005  0.0843 -0.0044\n",
      "\n",
      "Columns 30 to 39 \n",
      " 0.0673 -0.1204 -0.0742 -0.0408  0.0033  0.0845 -0.0387 -0.0690  0.0931 -0.0389\n",
      " 0.0983  0.1833 -0.0288  0.0393  0.0896  0.0125 -0.0035 -0.0087 -0.0752 -0.0158\n",
      "\n",
      "Columns 40 to 49 \n",
      " 0.0053 -0.0449  0.0282  0.0737 -0.2019  0.0550  0.0482  0.0345  0.0319  0.0083\n",
      "-0.0587 -0.0441 -0.0099  0.1053  0.2382 -0.0287  0.0612 -0.0146 -0.0828  0.0380\n",
      "\n",
      "Columns 50 to 59 \n",
      "-0.0588 -0.0329  0.0779  0.0204 -0.0839 -0.0471  0.0178  0.0030 -0.0057 -0.0254\n",
      " 0.0768 -0.0142 -0.0316  0.0174 -0.0416  0.0183 -0.0750 -0.0078  0.0246  0.0520\n",
      "\n",
      "Columns 60 to 69 \n",
      "-0.0572  0.0287 -0.0977 -0.1802 -0.0054  0.0770  0.0335  0.0135  0.0940  0.0025\n",
      "-0.0064 -0.0649 -0.0416  0.1632  0.0283 -0.0531  0.0462 -0.0106  0.0061  0.0015\n",
      "\n",
      "Columns 70 to 79 \n",
      "-0.0553 -0.0553  0.1408  0.0503 -0.1628 -0.0470  0.0265 -0.0632 -0.3240  0.1552\n",
      " 0.0719  0.0006 -0.1259 -0.0223  0.0909 -0.0446  0.0049  0.0489  0.2300  0.0186\n",
      "\n",
      "Columns 80 to 89 \n",
      " 0.0843 -0.0651 -0.1066  0.0411  0.0700  0.0254 -0.0536 -0.0685 -0.0706 -0.0419\n",
      "-0.0891  0.0288  0.0660  0.0218  0.0874  0.0820  0.0438  0.0270  0.0642  0.0385\n",
      "\n",
      "Columns 90 to 99 \n",
      "-0.1850  0.0056 -0.0471 -0.2808 -0.2001  0.0681  0.0311  0.0308 -0.0354  0.0674\n",
      " 0.2315  0.0168 -0.0458  0.2269  0.2647  0.0403 -0.0692  0.1170 -0.0542  0.0556\n",
      "\n",
      "Columns 100 to 103 \n",
      " 0.0273 -0.0228  0.0273  0.0181\n",
      "-0.0916  0.1191  0.0562  0.0538\n",
      "[torch.cuda.DoubleTensor of size 2x104 (GPU 0)]\n",
      "), ('fc4.bias', \n",
      " 0.9211\n",
      " 0.0650\n",
      "[torch.cuda.DoubleTensor of size 2 (GPU 0)]\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'inria trained model/'\n",
    "net = Net()\n",
    "net = net.double()\n",
    "net = net.cuda()\n",
    "print(net)\n",
    "name = input(\"Enter model name : \")\n",
    "PATH = MODEL_PATH + name\n",
    "net = torch.load(PATH)\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data = np.divide(data,255)\n",
    "    data = data - 0.5\n",
    "    return data\n",
    "def predictHuman(data):\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
